#!/usr/bin/env bash
set -euo pipefail

# === Config ===
OUT="${OUT:-as-is/exports}"                 # override with OUT=/path ./export_data_tier.sh
REGION="${AWS_REGION:-${REGION:-eu-west-1}}"# override with REGION=us-east-1 ./export_data_tier.sh
FILTER_NAME="${FILTER_NAME:-}"              # optional: grep filter for names/ids (e.g., ethos|portal|keycloak)

mkdir -p "$OUT"
echo "Exporting data-tier metadata to $OUT (region: $REGION)"
have_jq() { command -v jq >/dev/null 2>&1; }

# ---------- RDS / Aurora ----------
aws rds describe-db-instances --region "$REGION" > "$OUT/rds_instances.json"
aws rds describe-db-clusters  --region "$REGION" > "$OUT/rds_clusters.json"

if have_jq; then
  echo "Tagging RDS instances…"
  jq -r '.DBInstances[].DBInstanceArn' "$OUT/rds_instances.json" 2>/dev/null \
    | { if [ -n "$FILTER_NAME" ]; then grep -Ei "$FILTER_NAME" || true; else cat; fi; } \
    | while read -r ARN; do
        safe="$(echo "$ARN" | sed 's#.*:db:##')"
        aws rds list-tags-for-resource --resource-name "$ARN" --region "$REGION" > "$OUT/rds_tags_${safe}.json" || true
      done

  echo "Tagging RDS clusters…"
  jq -r '.DBClusters[].DBClusterArn' "$OUT/rds_clusters.json" 2>/dev/null \
    | { if [ -n "$FILTER_NAME" ]; then grep -Ei "$FILTER_NAME" || true; else cat; fi; } \
    | while read -r ARN; do
        safe="$(echo "$ARN" | sed 's#.*:cluster:##')"
        aws rds list-tags-for-resource --resource-name "$ARN" --region "$REGION" > "$OUT/rds_cluster_tags_${safe}.json" || true
      done
else
  echo "jq not found; skipping per-resource tag exports." >&2
fi

# ---------- DynamoDB ----------
aws dynamodb list-tables --region "$REGION" > "$OUT/ddb_tables.json"
if have_jq; then
  jq -r '.TableNames[]' "$OUT/ddb_tables.json" 2>/dev/null \
    | { if [ -n "$FILTER_NAME" ]; then grep -Ei "$FILTER_NAME" || true; else cat; fi; } \
    | while read -r T; do
        aws dynamodb describe-table --table-name "$T" --region "$REGION" > "$OUT/ddb_${T}.json" || true
      done
else
  echo "jq not found; export contains list only (no per-table describe)." >&2
fi

# ---------- Secrets Manager (metadata only) ----------
aws secretsmanager list-secrets --region "$REGION" > "$OUT/secrets_list.json"
if have_jq; then
  jq -r '.SecretList[].ARN' "$OUT/secrets_list.json" 2>/dev/null \
    | { if [ -n "$FILTER_NAME" ]; then grep -Ei "$FILTER_NAME" || true; else cat; fi; } \
    | while read -r SARN; do
        base="$(basename "$SARN")"
        aws secretsmanager get-resource-policy --secret-id "$SARN" --region "$REGION" > "$OUT/secret_policy_${base}.json" 2>/dev/null || true
      done
fi

echo "Done."



--------
# ----- RDS / Aurora -----
aws rds describe-db-instances --region "$REGION" > "$OUT/rds_instances.json"
aws rds describe-db-clusters  --region "$REGION" > "$OUT/rds_clusters.json"
# (optional) tags for identification
jq -r '.DBInstances[].DBInstanceArn' "$OUT/rds_instances.json" 2>/dev/null | while read -r ARN; do
  aws rds list-tags-for-resource --resource-name "$ARN" --region "$REGION" > "$OUT/rds_tags_$(echo "$ARN" | sed 's#.*:db:##').json" || true
done
jq -r '.DBClusters[].DBClusterArn' "$OUT/rds_clusters.json" 2>/dev/null | while read -r ARN; do
  aws rds list-tags-for-resource --resource-name "$ARN" --region "$REGION" > "$OUT/rds_cluster_tags_$(echo "$ARN" | sed 's#.*:cluster:##').json" || true
done

# ----- DynamoDB -----
aws dynamodb list-tables --region "$REGION" > "$OUT/ddb_tables.json"
jq -r '.TableNames[]' "$OUT/ddb_tables.json" 2>/dev/null | while read -r T; do
  aws dynamodb describe-table --table-name "$T" --region "$REGION" > "$OUT/ddb_${T}.json" || true
done

# ----- Secrets Manager (metadata only) -----
aws secretsmanager list-secrets --region "$REGION" > "$OUT/secrets_list.json"
# (optional) resource policies for posture evidence
jq -r '.SecretList[].ARN' "$OUT/secrets_list.json" 2>/dev/null | while read -r SARN; do
  aws secretsmanager get-resource-policy --secret-id "$SARN" --region "$REGION" > "$OUT/secret_policy_$(basename "$SARN").json" 2>/dev/null || true
done


---------

#!/usr/bin/env python3
import json, os, pathlib, re
from contextlib import suppress

# diagrams
from diagrams import Diagram, Cluster, Edge
from diagrams.aws.network import Route53, CloudFront, APIGateway, ELB, InternetGateway, PrivateSubnet, PublicSubnet
from diagrams.aws.compute import EKS, Lambda
from diagrams.aws.storage import S3
from diagrams.aws.database import RDS as RDSIcon, Aurora, Dynamodb
from diagrams.aws.security import SecretsManager

# Optional endpoint icon (not present in all versions)
try:
    from diagrams.aws.network import VPCEndpointInterface as VPCEndpointIcon
except Exception:
    VPCEndpointIcon = None

EXPORTS = pathlib.Path("as-is/exports")
OUTDIR  = pathlib.Path("diagrams")
OUTDIR.mkdir(exist_ok=True, parents=True)

def load_json(name):
    p = EXPORTS / name
    if not p.exists(): return None
    with open(p) as f: return json.load(f)

def first(lst, default=None):
    return lst[0] if lst else default

# ---------- Parsers ----------
def cf_summary():
    lst = (load_json("cf_distributions.json") or {}).get("DistributionList", {}).get("Items", [])
    if not lst: return None
    did = lst[0]["Id"]
    conf = (load_json(f"cf_{did}.json") or {}).get("Distribution", {}).get("DistributionConfig", {})
    aliases = conf.get("Aliases", {}).get("Items", []) or []
    return {"id": did, "aliases": aliases}

def apigw_v2_summary():
    items = (load_json("apigw_v2_apis.json") or {}).get("Items", [])
    if not items: return None
    api = items[0]; api_id = api.get("ApiId"); name = api.get("Name")
    integ = load_json(f"apigw_v2_{api_id}_integrations.json")
    nlb_links = []
    if integ and "Items" in integ:
        for it in integ["Items"]:
            uri = (it.get("IntegrationUri") or it.get("IntegrationUriArn") or "")
            if "elasticloadbalancing" in uri:
                nlb_links.append(uri)
    return {"id": api_id, "name": name, "nlb_links": nlb_links}

def nlb_summary():
    nlbs = load_json("elbv2_nlbs.json") or []
    if not nlbs:
        lbs = (load_json("elbv2_lbs.json") or {}).get("LoadBalancers", [])
        nlbs = [lb for lb in lbs if lb.get("Type") == "network"]
    if not nlbs: return None
    lb = nlbs[0]
    return {"name": lb.get("LoadBalancerName"), "dns": lb.get("DNSName")}

def eks_summary():
    names = (load_json("eks_clusters.json") or {}).get("clusters", [])
    if not names: return None
    return {"name": names[0]}

def detect_keycloak_name():
    # Look for 'keycloak' in k8s exports; fall back to generic
    for fname in EXPORTS.glob("eks_*_deploys.yaml"):
        try:
            txt = open(fname).read().lower()
            m = re.search(r'name:\s*keycloak[^\n]*', txt)
            if m: return "Keycloak (EKS)"
        except Exception:
            pass
    return "Keycloak"

def rds_pick():
    # Prefer clusters (Aurora) else instances; pick one matching 'ethos' if possible
    clusters = (load_json("rds_clusters.json") or {}).get("DBClusters", [])
    insts    = (load_json("rds_instances.json") or {}).get("DBInstances", [])
    pick = first([c for c in clusters if re.search(r'ethos|portal|keycloak', c.get("DBClusterIdentifier",""), re.I)], default=first(clusters))
    if pick:
        return {"type": "aurora", "id": pick.get("DBClusterIdentifier")}
    picki = first([i for i in insts if re.search(r'ethos|portal|keycloak', i.get("DBInstanceIdentifier",""), re.I)], default=first(insts))
    if picki:
        return {"type": "rds", "id": picki.get("DBInstanceIdentifier")}
    return None

def ddb_pick():
    names = (load_json("ddb_tables.json") or {}).get("TableNames", [])
    pick = first([n for n in names if re.search(r'ethos|portal', n, re.I)], default=first(names))
    return pick

def secrets_summary():
    secrets = (load_json("secrets_list.json") or {}).get("SecretList", [])
    # Only show 1-2 to keep diagram clean
    picks = [s for s in secrets if re.search(r'ethos|portal|eks|keycloak', (s.get("Name") or ""), re.I)]
    picks = picks or secrets[:1]
    return [s.get("Name") for s in picks[:2]]

# ---------- Diagrams ----------
GRAPH_STYLE = dict(
    rankdir="LR", splines="ortho", nodesep="1", ranksep="1.1", fontname="Helvetica", fontsize="12"
)

def draw_context_container():
    cf = cf_summary(); gw = apigw_v2_summary(); lb = nlb_summary(); eks = eks_summary()
    s3label = "S3 (static/state)"
    lambdas = (load_json("lambda_functions.json") or {}).get("Functions", [])
    lam = first([x["FunctionName"] for x in lambdas], "Lambda")

    rds = rds_pick()
    ddb = ddb_pick()
    secrets = secrets_summary()
    keycloak_name = detect_keycloak_name()

    with Diagram("Ethos Portal – Context & Containers", filename=str(OUTDIR/"01_context_container"),
                 show=False, outformat="png", graph_attr=GRAPH_STYLE):
        # Edge & CDN
        user = Route53("User")
        r53  = Route53("Route 53")
        cf_i = CloudFront(f"CloudFront\n{(cf or {}).get('id','')}")
        gw_i = APIGateway(f"API Gateway\n{(gw or {}).get('id','')}")
        nlb_i = ELB(f"NLB\n{(lb or {}).get('name','')}")
        s3_i = S3(s3label)
        lam_i = Lambda(lam)

        # EKS cluster & app containers
        with Cluster(f"EKS {(eks or {}).get('name','')}"):
            ingress = EKS("Ingress")
            backend = EKS("Backend Service")
            keycloak = EKS(keycloak_name)

        # Data stores & secrets
        if rds and rds["type"] == "aurora":
            rds_i = Aurora(f"Aurora\n{rds['id']}")
        elif rds:
            rds_i = RDSIcon(f"RDS\n{rds['id']}")
        else:
            rds_i = RDSIcon("RDS")

        ddb_i = Dynamodb(ddb or "DynamoDB")
        secnodes = [SecretsManager(n) for n in (secrets or ["Secrets Manager"])]

        # Flow
        user >> r53 >> cf_i
        cf_i >> Edge(label="static") >> s3_i
        cf_i >> Edge(label="dynamic") >> gw_i >> Edge(label="443/TLS") >> nlb_i >> Edge(label="ingress") >> ingress >> backend

        # Auth & storage decisions
        backend << Edge(label="OIDC/SAML") >> keycloak
        backend >> Edge(label="authorized (FIS)") >> rds_i
        backend >> Edge(style="dashed", label="external/unauth") >> ddb_i

        # Events & secrets use
        backend >> Edge(label="read/write") >> s3_i
        s3_i >> Edge(label="event") >> lam_i
        for s in secnodes:
            backend >> Edge(style="dotted", label="IRSA") >> s

def draw_request_path():
    cf = cf_summary(); gw = apigw_v2_summary(); lb = nlb_summary(); eks = eks_summary()
    with Diagram("Ethos Portal – API Request Path", filename=str(OUTDIR/"02_request_path"),
                 show=False, outformat="png", graph_attr=GRAPH_STYLE):
        user = Route53("Browser")
        r53  = Route53("Route 53")
        cf_i = CloudFront(f"CloudFront\n{(cf or {}).get('id','')}")
        gw_i = APIGateway(f"API GW\n{(gw or {}).get('id','')}")
        lb_i = ELB(f"NLB\n{(lb or {}).get('name','')}")
        with Cluster(f"EKS {(eks or {}).get('name','')}"):
            ingress = EKS("Ingress")
            svc     = EKS("Backend")
            keycloak = EKS("Keycloak")

        user >> Edge(label="HTTPS") >> r53 >> Edge(label="Alias") >> cf_i
        cf_i  >> Edge(label="HTTPS") >> gw_i >> Edge(label="TLS 443") >> lb_i >> Edge(label="TCP 443") >> ingress >> svc
        svc   << Edge(label="OIDC") >> keycloak

def draw_topology():
    with Diagram("Ethos Portal – VPC Topology (schematic)", filename=str(OUTDIR/"03_topology"),
                 show=False, outformat="png", graph_attr=GRAPH_STYLE):
        igw = InternetGateway("IGW")
        with Cluster("VPC (Ethos Portal)"):
            with Cluster("AZ-a"):
                pub_a = PublicSubnet("public-a")
                pri_a = PrivateSubnet("private-a")
                nlb_a = ELB("NLB ENI-a")

            with Cluster("AZ-b"):
                pub_b = PublicSubnet("public-b")
                pri_b = PrivateSubnet("private-b")
                nlb_b = ELB("NLB ENI-b")

            s3e = VPCEndpointIcon("S3 Endpoint") if VPCEndpointIcon else ELB("S3 Endpoint")

        igw >> pub_a
        igw >> pub_b
        nlb_a - pri_a; nlb_b - pri_b
        s3e - pri_a;   s3e - pri_b

if __name__ == "__main__":
    draw_context_container()
    draw_request_path()
    draw_topology()
    print(f"Wrote diagrams to {OUTDIR.resolve()}")

















----------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------
# macOS (Homebrew) / Linux
brew install graphviz || sudo apt-get install -y graphviz
python3 -m venv venv && source venv/bin/activate
pip install diagrams pyyaml

---------

#!/usr/bin/env python3
import json, os, pathlib, re
from contextlib import suppress

# diagrams (mingrammer)
from diagrams import Diagram, Cluster, Edge
from diagrams.aws.network import Route53, CloudFront, APIGateway, ELB, VPC, InternetGateway, VPCEndpoint
from diagrams.aws.network import PrivateSubnet, PublicSubnet
from diagrams.aws.compute import EKS, Lambda
from diagrams.aws.storage import S3

EXPORTS = pathlib.Path("as-is/exports")
OUTDIR  = pathlib.Path("diagrams")
OUTDIR.mkdir(exist_ok=True, parents=True)

def load_json(path):
    p = EXPORTS / path
    if not p.exists(): return None
    with open(p) as f:
        return json.load(f)

def first(items, key=None, default=None):
    if not items: return default
    return items[0] if key is None else next((i for i in items if key(i)), default)

# ---------- Parsers (best-effort) ----------
def pick_vpc():
    vpcs = load_json("vpcs.json") or {}
    arr = vpcs.get("Vpcs", [])
    return first(arr, default={"VpcId": "vpc-unknown"})

def list_subnets(vpc_id):
    subnets = (load_json("subnets.json") or {}).get("Subnets", [])
    # Filter by VPC
    subs = [s for s in subnets if s.get("VpcId")==vpc_id]
    # Decide public vs private: MapPublicIpOnLaunch is a decent heuristic
    pubs = [s for s in subs if s.get("MapPublicIpOnLaunch")]
    pris = [s for s in subs if not s.get("MapPublicIpOnLaunch")]
    # group by AZ (up to 2 for aesthetics)
    def by_az(xs): 
        d={}
        for s in xs:
            d.setdefault(s["AvailabilityZone"], []).append(s)
        return d
    return by_az(pubs), by_az(pris)

def cf_summary():
    dist = load_json("cf_distributions.json") or {}
    items = dist.get("DistributionList", {}).get("Items", [])
    if not items: 
        return None
    did = items[0]["Id"]
    full = load_json(f"cf_{did}.json") or {}
    conf = full.get("Distribution", {}).get("DistributionConfig", {})
    origins = [o.get("DomainName") for o in conf.get("Origins", {}).get("Items", [])]
    aliases = conf.get("Aliases", {}).get("Items", [])
    return {"id": did, "origins": origins, "aliases": aliases}

def apigw_v2_summary():
    apis = load_json("apigw_v2_apis.json") or {}
    items = apis.get("Items", [])
    if not items: return None
    api = items[0]
    api_id = api.get("ApiId"); name = api.get("Name")
    # Try to find integration to ELB/NLB
    integ = load_json(f"apigw_v2_{api_id}_integrations.json")
    tgts = []
    if integ and "Items" in integ:
        for it in integ["Items"]:
            uri = (it.get("IntegrationUri") or it.get("IntegrationUriArn") or "")
            if "elasticloadbalancing" in uri:
                tgts.append(uri)
    return {"id": api_id, "name": name, "nlb_links": tgts}

def nlb_summary():
    nlbs = load_json("elbv2_nlbs.json") or []
    if not nlbs: 
        # fallback: filter from full LB list
        lbs = (load_json("elbv2_lbs.json") or {}).get("LoadBalancers", [])
        nlbs = [lb for lb in lbs if lb.get("Type") == "network"]
    if not nlbs: 
        return None
    lb = nlbs[0]
    return {
        "arn": lb.get("LoadBalancerArn"),
        "name": lb.get("LoadBalancerName"),
        "dns": lb.get("DNSName"),
        "vpc": lb.get("VpcId"),
        "scheme": lb.get("Scheme"),
        "azs": [z.get("ZoneName") for z in lb.get("AvailabilityZones", [])],
    }

def eks_summary():
    cl = load_json("eks_clusters.json") or {}
    names = cl.get("clusters", [])
    if not names: return None
    name = names[0]
    desc = load_json(f"eks_{name}.json") or {}
    ver  = desc.get("cluster", {}).get("version")
    return {"name": name, "version": ver}

def s3_brief():
    b = load_json("s3_buckets.json") or {}
    names = [x["Name"] for x in b.get("Buckets", [])]
    return names[:3]  # keep the diagram clean

def lambda_brief():
    f = load_json("lambda_functions.json") or {}
    items = f.get("Functions", [])
    return [x.get("FunctionName") for x in items[:2]]  # max two icons on diagram

# ---------- Diagram 1: Context/Container ----------
def draw_context_container():
    cf = cf_summary()
    apigw = apigw_v2_summary()
    nlb = nlb_summary()
    eks = eks_summary()
    s3s = s3_brief()
    lambdas = lambda_brief()

    title = "Ethos Portal – Context & Containers"
    filename = str(OUTDIR / "01_context_container")

    with Diagram(title, filename=filename, show=False, outformat="png"):
        user = Route53("User via DNS")  # Just to keep icon variety; we’ll add real R53 next line
        r53  = Route53("Route 53")
        cf_i = CloudFront(f"CloudFront\n{cf['id'] if cf else ''}")
        apigw_i = APIGateway(f"API Gateway\n{apigw['id'] if apigw else ''}")
        nlb_i = ELB(f"NLB\n{(nlb or {}).get('name','')}")
        eks_i = EKS(f"EKS\n{(eks or {}).get('name','')}")
        s3_i  = S3("S3 (static/state)")
        # Keep Lambdas compact
        l_nodes = [Lambda(n) for n in lambdas] if lambdas else [Lambda("Lambda")]

        user >> r53 >> cf_i
        cf_i >> Edge(label="static") >> s3_i
        cf_i >> Edge(label="dynamic") >> apigw_i >> Edge(label="443/TLS") >> nlb_i >> Edge(label="ingress") >> eks_i
        # side paths
        eks_i >> Edge(label="read/write") >> s3_i
        s3_i >> Edge(label="event") >> l_nodes[0]

# ---------- Diagram 2: Request Path (icons w/ arrows) ----------
def draw_request_path():
    cf = cf_summary(); apigw = apigw_v2_summary(); nlb = nlb_summary(); eks = eks_summary()

    title = "Ethos Portal – API Request Path"
    filename = str(OUTDIR / "02_request_path")

    with Diagram(title, filename=filename, show=False, outformat="png"):
        user = Route53("Browser")
        r53  = Route53("Route 53")
        cf_i = CloudFront(f"CloudFront\n{cf['id'] if cf else ''}")
        gw   = APIGateway(f"API GW\n{(apigw or {}).get('id','')}")
        lb   = ELB(f"NLB\n{(nlb or {}).get('name','')}")
        ing  = EKS(f"Ingress (EKS)\n{(eks or {}).get('name','')}")

        user >> Edge(label="HTTPS") >> r53 >> Edge(label="Alias") >> cf_i
        cf_i >> Edge(label="HTTPS") >> gw >> Edge(label="TLS 443") >> lb >> Edge(label="TCP 443") >> ing

# ---------- Diagram 3: Network Topology ----------
def draw_topology():
    vpc = pick_vpc().get("VpcId")
    pubs_by_az, pris_by_az = list_subnets(vpc)
    nlb = nlb_summary()

    title = f"Ethos Portal – VPC Topology ({vpc})"
    filename = str(OUTDIR / "03_topology")

    with Diagram(title, filename=filename, show=False, outformat="png"):
        igw = InternetGateway("IGW")
        with Cluster(f"VPC {vpc}"):
            # draw at most two AZs to keep legible
            az_names = sorted(set(list(pubs_by_az.keys()) + list(pris_by_az.keys())))[:2]
            az_clusters = []
            for az in az_names:
                with Cluster(f"{az}"):
                    # Public subnets
                    pub_nodes = []
                    for s in pubs_by_az.get(az, [])[:1]:
                        pub_nodes.append(PublicSubnet(f"{s['SubnetId']}"))
                    # Private subnets
                    pri_nodes = []
                    for s in pris_by_az.get(az, [])[:1]:
                        pri_nodes.append(PrivateSubnet(f"{s['SubnetId']}"))
                    # Drop an NLB ENI per AZ (symbolically)
                    nlb_node = ELB(f"NLB ENI\n{(nlb or {}).get('name','')}")
                    az_clusters.append((pub_nodes, pri_nodes, nlb_node))

            # S3 Gateway/Interface Endpoint (symbolic)
            s3e = VPCEndpoint("S3 VPC Endpoint")

        # Connect IGW to first public subnets (if any)
        with suppress(Exception):
            if az_clusters and az_clusters[0][0]:
                igw >> az_clusters[0][0][0]
            if len(az_clusters) > 1 and az_clusters[1][0]:
                igw >> az_clusters[1][0][0]

        # NLB sits in private subnets here (common pattern with Ingress)
        for (_, pri_nodes, nlb_node) in az_clusters:
            if pri_nodes:
                nlb_node - pri_nodes[0]
        # VPC endpoint links
        for (_, pri_nodes, _) in az_clusters:
            if pri_nodes:
                s3e - pri_nodes[0]

# ---------- Run ----------
if __name__ == "__main__":
    draw_context_container()
    draw_request_path()
    draw_topology()
    print(f"Diagrams written to {OUTDIR.resolve()}")




----

python generate_ethos_diagrams.py
# -> diagrams/01_context_container.png
# -> diagrams/02_request_path.png
# -> diagrams/03_topology.png





----------------
#!/usr/bin/env bash
set -euo pipefail

# ===== config =====
OUT="as-is/exports"
REGION="${AWS_REGION:-$(aws configure get region || echo eu-west-1)}"
mkdir -p "$OUT"

echo "Exporting Ethos Portal as-is to $OUT (region: $REGION)"

# ----- Identity & scope -----
aws sts get-caller-identity > "$OUT/whoami.json"
aws ec2 describe-vpcs --region "$REGION" > "$OUT/vpcs.json"
aws ec2 describe-subnets --region "$REGION" > "$OUT/subnets.json"
aws ec2 describe-vpc-endpoints --region "$REGION" > "$OUT/vpce.json"
aws ec2 describe-security-groups --region "$REGION" > "$OUT/sgs.json"
aws ec2 describe-route-tables --region "$REGION" > "$OUT/routes.json"

# ----- Edge + DNS + CDN -----
aws route53 list-hosted-zones > "$OUT/r53_zones.json"
# loop zones to fetch records
jq -r '.HostedZones[].Id' "$OUT/r53_zones.json" | sed 's#/hostedzone/##' | while read -r HZID; do
  aws route53 list-resource-record-sets --hosted-zone-id "$HZID" > "$OUT/r53_records_${HZID}.json"
done

aws cloudfront list-distributions > "$OUT/cf_distributions.json"
# fetch full config per distribution (origins/behaviors/TLS)
jq -r '.DistributionList.Items[].Id' "$OUT/cf_distributions.json" 2>/dev/null | while read -r DID; do
  aws cloudfront get-distribution --id "$DID" > "$OUT/cf_${DID}.json"
done

# ----- API layer (v2 + v1) -----
aws apigatewayv2 get-apis --region "$REGION" > "$OUT/apigw_v2_apis.json"
# Optional: domain names (custom domains)
aws apigatewayv2 get-domain-names --region "$REGION" > "$OUT/apigw_v2_domains.json"
# loop v2 apis for stages/integrations/routes/authorizers
jq -r '.Items[].ApiId' "$OUT/apigw_v2_apis.json" 2>/dev/null | while read -r API; do
  aws apigatewayv2 get-stages --api-id "$API" --region "$REGION" > "$OUT/apigw_v2_${API}_stages.json"
  aws apigatewayv2 get-integrations --api-id "$API" --region "$REGION" > "$OUT/apigw_v2_${API}_integrations.json"
  aws apigatewayv2 get-routes --api-id "$API" --region "$REGION" > "$OUT/apigw_v2_${API}_routes.json"
  aws apigatewayv2 get-authorizers --api-id "$API" --region "$REGION" > "$OUT/apigw_v2_${API}_authorizers.json"
done

aws apigateway get-rest-apis --region "$REGION" > "$OUT/apigw_v1_apis.json"
aws apigateway get-domain-names --region "$REGION" > "$OUT/apigw_v1_domains.json"
# lightweight per-REST API (full per-method integrations are very heavy; skip for one-time doc)
jq -r '.items[].id' "$OUT/apigw_v1_apis.json" 2>/dev/null | while read -r RID; do
  aws apigateway get-stages --rest-api-id "$RID" --region "$REGION" > "$OUT/apigw_v1_${RID}_stages.json"
  aws apigateway get-resources --rest-api-id "$RID" --region "$REGION" > "$OUT/apigw_v1_${RID}_resources.json"
done

# ----- Load balancer (focus on NLBs) -----
aws elbv2 describe-load-balancers --region "$REGION" > "$OUT/elbv2_lbs.json"
# Filter NLBs for convenience (still keep the full file above)
aws elbv2 describe-load-balancers --region "$REGION" \
  --query 'LoadBalancers[?Type==`network`]' > "$OUT/elbv2_nlbs.json"

# loop NLB ARNs for listeners, attributes, and target groups
jq -r '.[].LoadBalancerArn' "$OUT/elbv2_nlbs.json" 2>/dev/null | while read -r LARN; do
  LID=$(basename "$LARN")
  aws elbv2 describe-listeners --load-balancer-arn "$LARN" --region "$REGION" > "$OUT/elbv2_${LID}_listeners.json"
  aws elbv2 describe-load-balancer-attributes --load-balancer-arn "$LARN" --region "$REGION" > "$OUT/elbv2_${LID}_attrs.json"
  # target groups for this LB
  aws elbv2 describe-target-groups --load-balancer-arn "$LARN" --region "$REGION" > "$OUT/elbv2_${LID}_tgs.json"
  jq -r '.TargetGroups[].TargetGroupArn' "$OUT/elbv2_${LID}_tgs.json" 2>/dev/null | while read -r TGARN; do
    TID=$(basename "$TGARN")
    aws elbv2 describe-target-health --target-group-arn "$TGARN" --region "$REGION" > "$OUT/elbv2_tg_${TID}_health.json"
    aws elbv2 describe-target-group-attributes --target-group-arn "$TGARN" --region "$REGION" > "$OUT/elbv2_tg_${TID}_attrs.json"
  done
done

# ----- EKS control plane & k8s ingress/services -----
aws eks list-clusters --region "$REGION" > "$OUT/eks_clusters.json"
jq -r '.clusters[]' "$OUT/eks_clusters.json" 2>/dev/null | while read -r CL; do
  aws eks describe-cluster --name "$CL" --region "$REGION" > "$OUT/eks_${CL}.json"
  # kubeconfig + cluster scrape (requires your IAM/kubectl can auth to EKS)
  aws eks update-kubeconfig --name "$CL" --region "$REGION" >/dev/null
  kubectl get ingressclass -A -o yaml > "$OUT/eks_${CL}_ingressclass.yaml" || true
  kubectl get ingress -A -o yaml       > "$OUT/eks_${CL}_ingress.yaml" || true
  kubectl get svc -A -o yaml           > "$OUT/eks_${CL}_services.yaml" || true
  kubectl get deploy -A -o yaml        > "$OUT/eks_${CL}_deploys.yaml" || true
done

# ----- Lambda & S3 (PCI-relevant) -----
aws lambda list-functions --region "$REGION" > "$OUT/lambda_functions.json"

aws s3api list-buckets > "$OUT/s3_buckets.json"
jq -r '.Buckets[].Name' "$OUT/s3_buckets.json" | while read -r B; do
  aws s3api get-bucket-encryption --bucket "$B" > "$OUT/s3_${B}_enc.json" 2>/dev/null || true
  aws s3api get-public-access-block --bucket "$B" > "$OUT/s3_${B}_pab.json" 2>/dev/null || true
  aws s3api get-bucket-versioning --bucket "$B" > "$OUT/s3_${B}_ver.json" 2>/dev/null || true
  aws s3api get-bucket-policy-status --bucket "$B" > "$OUT/s3_${B}_policy_status.json" 2>/dev/null || true
  aws s3api get-bucket-ownership-controls --bucket "$B" > "$OUT/s3_${B}_ownership.json" 2>/dev/null || true
done

echo "Done. JSON exports in $OUT"
