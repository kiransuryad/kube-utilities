@Library(['common-lib3-stable']) _

properties([
  parameters([
    string(name: 'IMAGE_NAME', defaultValue: 'ethos-portal-unauth', description: 'Image name'),
    string(name: 'IMAGE_TAG', defaultValue: '1.61.0-3-unauth-uat', description: 'Tag to migrate')
  ])
])

// ---------------------
// POD TEMPLATE
// ---------------------
String podTemplateString = """
apiVersion: v1
kind: Pod
spec:
  containers:
    - name: aws
      image: caas-docker-release-local.docker.fis.dev/jenkins/ubi8-minimal-hel-aws:3.6.3-1
      tty: true
      command: ['cat']
      resources:
        limits:
          github.com/fuse: 1

    - name: jdk11
      image: caas-docker-release-local.docker.fis.dev/jenkins/ubi8-minimal-jdk11-maven:3.8.4-1
      tty: true
      command: ['cat']
      resources:
        limits:
          github.com/fuse: 1

  imagePullSecrets:
    - name: caas-docker-release-local-ro

  serviceAccountName: jenkins
"""

def label = "ecr-artifactory-${UUID.randomUUID().toString()}"

podTemplate(label: label, yaml: podTemplateString, runAsUser: '1000') {

  node(label) {

    // ---------------------
    // ENV / CONSTANTS
    // ---------------------
    env.OLD_AWS_ACCOUNT   = "588633075404"
    env.OLD_AWS_REGION    = "us-east-1"

    env.ARTIFACTORY_URL   = "artifactory.fis.dev"
    env.ARTIFACTORY_REPO  = "dsdata-docker-snapshot-local"

    stage("Checkout Tools Repo") {
      checkout([
        $class: 'GitSCM',
        branches: [[name: "*/develop"]],
        userRemoteConfigs: [[
          url: "https://bitbucket.fis.dev/scm/dsdata/ethos-tools-devops.git",
          credentialsId: "ethos-portal-svc-acct"
        ]]
      ])
    }

    // ---------------------
    // LOAD JFROG SECRET FROM VAULT
    // ---------------------
    stage("Load JFrog API Key") {
      withCredentials([
        string(credentialsId: 'svcacct-dsdata-caas-snapshot', variable: 'JFROG_API_KEY')
      ]) {
        env.JFROG_USER="svcacct-dsdata-caas-snapshot"
      }
    }

    // ---------------------
    // AUTH AWS
    // ---------------------
    stage("Authenticate to old AWS ECR") {
      withCredentials([[
        $class: 'AmazonWebServicesCredentialsBinding',
        credentialsId: 'ASIAYSDKD53GLQBFWEDL'
      ]]) {
        container('aws') {
          sh """
          aws sts get-caller-identity
          export ECR_PASSWORD=\$(aws ecr get-login-password --region ${env.OLD_AWS_REGION})
          echo "AWS ECR login successful"
          """
        }
      }
    }

    // ---------------------
    // COPY IMAGE USING SKOPEO
    // ---------------------
    stage("Copy Image from ECR to Artifactory") {
      container('aws') {
        sh """
        echo "Copying ${params.IMAGE_NAME}:${params.IMAGE_TAG}"

        skopeo copy \
          --override-os linux \
          --override-arch amd64 \
          --src-creds "AWS:\$ECR_PASSWORD" \
          --dest-creds "${env.JFROG_USER}:${env.JFROG_API_KEY}" \
          docker://${env.OLD_AWS_ACCOUNT}.dkr.ecr.${env.OLD_AWS_REGION}.amazonaws.com/${params.IMAGE_NAME}:${params.IMAGE_TAG} \
          docker://${env.ARTIFACTORY_URL}/${env.ARTIFACTORY_REPO}/${params.IMAGE_NAME}:${params.IMAGE_TAG}
        """
      }
    }
    // ---------------------
    // COPY IMAGE USING Buildah
    // ---------------------
stage("Copy Image using Buildah") {
  container('aws') {

    withCredentials([[
      $class: 'AmazonWebServicesCredentialsBinding',
      credentialsId: 'ASIAYSDKD53GLQBFWEDL'
    ]]) {

      withCredentials([string(credentialsId: 'svcacct-dsdata-caas-snapshot', variable: 'JFROG_API_KEY')]) {

        sh """
        echo "Logging into AWS ECR‚Ä¶"
        export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID
        export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY
        export AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN

        export ECR_PASSWORD=\$(aws ecr get-login-password --region ${env.OLD_AWS_REGION})

        echo "Logging into Artifactory‚Ä¶"
        buildah login -u svcacct-dsdata-caas-snapshot -p $JFROG_API_KEY ${env.ARTIFACTORY_URL}

        echo "Pulling from ECR‚Ä¶"
        buildah pull --tls-verify=false \
          "docker://${env.OLD_AWS_ACCOUNT}.dkr.ecr.${env.OLD_AWS_REGION}.amazonaws.com/${params.IMAGE_NAME}:${params.IMAGE_TAG}"

        echo "Tagging for Artifactory‚Ä¶"
        buildah tag \
          "docker://${env.OLD_AWS_ACCOUNT}.dkr.ecr.${env.OLD_AWS_REGION}.amazonaws.com/${params.IMAGE_NAME}:${params.IMAGE_TAG}" \
          "${env.ARTIFACTORY_URL}/${env.ARTIFACTORY_REPO}/${params.IMAGE_NAME}:${params.IMAGE_TAG}"

        echo "Pushing to Artifactory‚Ä¶"
        buildah push --tls-verify=false \
          "${env.ARTIFACTORY_URL}/${env.ARTIFACTORY_REPO}/${params.IMAGE_NAME}:${params.IMAGE_TAG}"

        echo "Done! Buildah copy successful."
        """
      }
    }
  }
}


    stage("Done") {
      echo "Image migrated successfully ‚Üí ${env.ARTIFACTORY_URL}/${env.ARTIFACTORY_REPO}/${params.IMAGE_NAME}:${params.IMAGE_TAG}"
    }
  }
}













-------------------------------------------------------
pipeline {
    agent any

    environment {
        OLD_ACCOUNT_ID = "588633075404"
        OLD_REGION     = "us-east-1"
        IMAGE_NAME     = "ethos-portal"
        IMAGE_TAG      = "1.61.0-3-unauth-uat"

        NEW_ARTIFACTORY_URL  = "artifactory.fis.dev/artifactory"
        NEW_ARTIFACTORY_REPO = "dsdata-docker-snapshot-local"
        NEW_ARTIFACTORY_IMAGE = "ethos-portal-unauth"

        // Username is static (not in Vault secret)
        JFROG_USER = "svcacct-dsdata-caas-snapshot"
    }

    stages {

        stage('Load JFrog API Key from Vault') {
            steps {
                withVault([
                    vaultSecrets: [
                        [
                            path: 'jenkins/artifactory-svc-acct-snapshot',
                            secretValues: [
                                [envVar: 'JFROG_API_KEY', vaultKey: 'svcacct-dsdata-caas-snapshot']
                            ]
                        ]
                    ]
                ]) {
                    sh '''
                        echo "JFrog user loaded = ${JFROG_USER}"
                        echo "JFrog API key length = ${#JFROG_API_KEY}"
                    '''
                }
            }
        }

        stage('Authenticate to AWS ECR') {
            steps {
                withCredentials([aws(
                    credentialsId: 'ASIAYSDKD53GLQBFWEDL',
                    accessKeyVariable: 'AWS_ACCESS_KEY_ID',
                    secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
                )]) {
                    sh '''
                        echo "üîê Logging into AWS ECR..."
                        export AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
                        export AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}

                        ECR_PASSWORD=$(aws ecr get-login-password --region ${OLD_REGION})
                        echo "${ECR_PASSWORD}" > ecr_pass.txt
                    '''
                }
            }
        }

        stage('Copy Image from ECR to Artifactory') {
            steps {
                sh '''
                    echo "üöÄ Copying image using Skopeo..."

                    skopeo copy \
                      --override-os linux \
                      --override-arch amd64 \
                      --src-creds "AWS:$(cat ecr_pass.txt)" \
                      --dest-creds "${JFROG_USER}:${JFROG_API_KEY}" \
                      docker://${OLD_ACCOUNT_ID}.dkr.ecr.${OLD_REGION}.amazonaws.com/${IMAGE_NAME}:${IMAGE_TAG} \
                      docker://${NEW_ARTIFACTORY_URL}/${NEW_ARTIFACTORY_REPO}/${NEW_ARTIFACTORY_IMAGE}:${IMAGE_TAG}

                    echo "üéâ Image migration completed successfully!"
                '''
            }
        }
    }
}





------------------------------------------------------------------
#!/bin/bash
set -e

###########################################
# CONFIGURATION
###########################################

# Old AWS Account Details (ECR Source)
OLD_ACCOUNT_ID="<OLD_ACCOUNT_ID>"
OLD_REGION="eu-west-2"

# Image you want to migrate
IMAGE_NAME="<IMAGE_NAME>"        # e.g. ethos-portal-auth
IMAGE_TAG="<IMAGE_TAG>"          # e.g. 1.0.0

# New Artifactory (Destination)
# Example: mycompany.jfrog.io/hydra-docker-virtual
NEW_ARTIFACTORY_URL="<ARTIFACTORY_URL>"
NEW_ARTIFACTORY_USER="<JFROG_USER>"
NEW_ARTIFACTORY_API_KEY="<JFROG_API_KEY>"

###########################################
# START
###########################################

echo "-----------------------------------------------------"
echo " üîê Logging into OLD ECR"
echo "-----------------------------------------------------"

aws ecr get-login-password --region $OLD_REGION \
  | docker login --username AWS --password-stdin \
    ${OLD_ACCOUNT_ID}.dkr.ecr.${OLD_REGION}.amazonaws.com

echo ""
echo "-----------------------------------------------------"
echo " ‚¨áÔ∏è Pulling image from OLD ECR"
echo "-----------------------------------------------------"

SOURCE_IMAGE="${OLD_ACCOUNT_ID}.dkr.ecr.${OLD_REGION}.amazonaws.com/${IMAGE_NAME}:${IMAGE_TAG}"

docker pull $SOURCE_IMAGE

echo ""
echo "-----------------------------------------------------"
echo " üîÑ Retagging for Artifactory"
echo "-----------------------------------------------------"

TARGET_IMAGE="${NEW_ARTIFACTORY_URL}/${IMAGE_NAME}:${IMAGE_TAG}"

docker tag $SOURCE_IMAGE $TARGET_IMAGE

echo ""
echo "-----------------------------------------------------"
echo " üîê Logging into Artifactory"
echo "-----------------------------------------------------"

docker login $NEW_ARTIFACTORY_URL \
  -u $NEW_ARTIFACTORY_USER \
  -p $NEW_ARTIFACTORY_API_KEY

echo ""
echo "-----------------------------------------------------"
echo " ‚¨ÜÔ∏è Pushing image to Artifactory"
echo "-----------------------------------------------------"

docker push $TARGET_IMAGE

echo ""
echo "-----------------------------------------------------"
echo " ‚úÖ Migration Complete!"
echo "-----------------------------------------------------"
echo "Old ECR Image : $SOURCE_IMAGE"
echo "New Artifactory: $TARGET_IMAGE"
echo "-----------------------------------------------------"



----------------------------------------------------------------------------------------
#!/usr/bin/env python3
# Proposed architecture for Ethos Portal (Akamai front + external Vault)
# Requires: pip install diagrams graphviz

from diagrams import Diagram, Cluster, Edge
from diagrams.aws.network import APIGateway, ELB
from diagrams.aws.compute import EKS, Lambda
from diagrams.aws.storage import S3
from diagrams.aws.database import RDS as RDSIcon, Aurora, Dynamodb
from diagrams.onprem.security import Vault as VaultIcon
from diagrams.generic.blank import Blank   # generic box we can label "Akamai"
from diagrams.onprem.client import Users

# ---- knobs ----
TITLE = "Ethos Portal ‚Äì Proposed Architecture (Akamai + Vault)"
USE_CLOUDFRONT = False  # set True to show CF as origin shield / multi-CDN

GRAPH_ATTR = dict(
    rankdir="LR", splines="ortho", nodesep="1.1", ranksep="1.2", pad="0.2"
)
NODE_ATTR  = dict(fontname="Helvetica", fontsize="12", margin="0.06,0.04")
EDGE_ATTR  = dict(arrowsize="0.9", penwidth="1.2", labelfontsize="10",
                  tailclip="true", headclip="true")

def draw():
    with Diagram(TITLE, filename="proposed_ethos_portal", show=False, outformat="png",
                 graph_attr=GRAPH_ATTR, node_attr=NODE_ATTR, edge_attr=EDGE_ATTR):

        user = Users("End-User / Browser")
        akamai = Blank("Akamai (DNS + CDN)")  # front door

        if USE_CLOUDFRONT:
            # Optional: CF as origin shield / AWS edge features (Lambda@Edge/OAC)
            from diagrams.aws.network import CloudFront
            cf = CloudFront("CloudFront (optional)")
            user >> Edge(label="HTTPS") >> akamai >> Edge(label="origin fetch") >> cf
            edge_source = cf
        else:
            user >> Edge(label="HTTPS") >> akamai
            edge_source = akamai

        # Dynamic path
        apigw = APIGateway("API Gateway (HTTP)")
        nlb   = ELB("NLB (TLS 443)")

        # EKS app cluster
        with Cluster("EKS Cluster (Private VPC)"):
            ingress = EKS("Ingress")
            backend = EKS("Backend Service")
            keycloak = EKS("Keycloak (Auth)")

        # Static/objects and async
        s3 = S3("S3 (static/assets/state)")
        lam = Lambda("Lambda (S3 events)")

        # Data stores
        rds = Aurora("Aurora (authorized FIS users)")  # change to RDSIcon(...) if needed
        ddb = Dynamodb("DynamoDB (external/unauth)")

        # External secrets
        vault = VaultIcon("HashiCorp Vault\n(FIS external)")

        # --- Flows ---
        # Dynamic requests
        edge_source >> Edge(label="dynamic HTTPS") >> apigw \
                    >> Edge(label="TLS 443") >> nlb \
                    >> Edge(label="ingress") >> ingress >> backend

        # Static content
        edge_source >> Edge(label="static HTTPS") >> s3

        # Auth in-cluster
        backend << Edge(label="OIDC/SAML") >> keycloak

        # Data write paths
        backend >> Edge(label="authorized (FIS)") >> rds
        backend >> Edge(style="dashed", label="external/unauth") >> ddb

        # S3 events
        backend >> Edge(label="read/write") >> s3
        s3 >> Edge(label="event") >> lam

        # Secrets from external Vault
        backend >> Edge(style="dotted", label="AppRole/JWT") >> vault
        keycloak >> Edge(style="dotted", label="AppRole/JWT") >> vault

if __name__ == "__main__":
    draw()
    print("Wrote proposed_ethos_portal.png")










------------------------------------------------------------------------------------------
def emit_mermaid_context(drawio_path="01_context_container.mmd", md_path=None):
    cf  = (cf_summary() or {})
    gw  = (apigw_v2_summary() or {})
    lb  = (nlb_summary() or {})
    eks = (eks_summary() or {})
    rds = rds_pick()
    ddb = ddb_pick()
    keycloak = detect_keycloak_name()
    s3label = "S3 (static/state)"

    cf_label  = f"CloudFront {cf.get('id','')}".strip()
    gw_label  = f"API Gateway {gw.get('id','')}".strip()
    lb_label  = f"NLB {lb.get('name','')}".strip()
    eks_label = (eks.get("name") or "EKS").strip()

    if rds and rds.get("type") == "aurora":
        rds_label = f"Aurora {rds.get('id','')}".strip()
    elif rds:
        rds_label = f"RDS {rds.get('id','')}".strip()
    else:
        rds_label = "RDS"

    ddb_label = (ddb or "DynamoDB").strip()

    # Use '-- text -->' (NOT the '|text|' form) for maximum draw.io compatibility.
    lines = [
        "flowchart LR",
        "  U[User] --> R53[Route 53] --> CF[" + cf_label + "]",
        "  CF -- static --> S3[" + s3label + "]",
        "  CF -- dynamic --> GW[" + gw_label + "]",
        "  GW -- 443/TLS --> NLB[" + lb_label + "]",
        "  subgraph EKS[" + eks_label + "]",
        "    ING[Ingress] --> BE[Backend Service]",
        "    BE -- OIDC/SAML --> KC[" + keycloak + "]",
        "  end",
        "  NLB -- ingress --> ING",
        "  BE -- authorized (FIS) --> RDS[" + rds_label + "]",
        "  BE -. external/unauth .-> DDB[" + ddb_label + "]",
        "  BE -- read/write --> S3",
    ]
    mermaid_raw = "\n".join(lines)

    (OUTDIR / drawio_path).write_text(mermaid_raw)
    if md_path:
        (OUTDIR / md_path).write_text("```mermaid\n" + mermaid_raw + "\n```")








-----------------------------------------------------------------------------------------------------------
def emit_mermaid_context(drawio_path="01_context_container.mmd", md_path=None):
    cf  = cf_summary() or {}
    gw  = apigw_v2_summary() or {}
    lb  = nlb_summary() or {}
    eks = eks_summary() or {}
    rds = rds_pick()
    ddb = ddb_pick()
    keycloak = detect_keycloak_name()
    s3label = "S3 (static/state)"

    # Build labels (no backslashes/newlines inside {} for safety)
    cf_label  = f"CloudFront {cf.get('id','')}".strip()
    gw_label  = f"API Gateway {gw.get('id','')}".strip()
    lb_label  = f"NLB {lb.get('name','')}".strip()
    eks_label = (eks.get("name") or "EKS").strip()

    if rds and rds.get("type") == "aurora":
        rds_label = f"Aurora {rds.get('id','')}".strip()
    elif rds:
        rds_label = f"RDS {rds.get('id','')}".strip()
    else:
        rds_label = "RDS"

    ddb_label = (ddb or "DynamoDB").strip()

    lines = [
        "flowchart LR",
        "  U[User] --> R53[Route 53] --> CF[" + cf_label + "]",
        "  CF -->|static| S3[" + s3label + "]",
        "  CF -->|dynamic| GW[" + gw_label + "]",
        "  GW -->|443/TLS| NLB[" + lb_label + "]",
        "  subgraph EKS[" + eks_label + "]",
        "    ING[Ingress] --> BE[Backend Service]",
        "    BE -- OIDC/SAML --> KC[" + keycloak + "]",
        "  end",
        "  NLB -->|ingress| ING",
        "  BE -->|authorized (FIS)| RDS[" + rds_label + "]",
        "  BE -.->|external/unauth| DDB[" + ddb_label + "]",
        "  BE -->|read/write| S3",
    ]
    mermaid_raw = "\n".join(lines)

    # Write raw Mermaid for draw.io
    (OUTDIR / drawio_path).write_text(mermaid_raw)

    # Optional: also write a Markdown-flavored copy with fences (for Confluence/GitHub)
    if md_path:
        (OUTDIR / md_path).write_text("```mermaid\n" + mermaid_raw + "\n```")









---------------------------------------------------
def emit_mermaid_context(path):
    cf  = cf_summary() or {}
    gw  = apigw_v2_summary() or {}
    lb  = nlb_summary() or {}
    eks = eks_summary() or {}
    rds = rds_pick()
    ddb = ddb_pick()
    keycloak = detect_keycloak_name()
    s3label = "S3 (static/state)"

    # --- Build labels OUTSIDE of {} to avoid backslashes inside f-string expressions ---
    cf_label  = f"CloudFront\\n{cf.get('id','')}"
    gw_label  = f"API Gateway\\n{gw.get('id','')}"
    lb_label  = f"NLB\\n{lb.get('name','')}"
    eks_label = f"{eks.get('name','') or 'EKS'}"

    rds_title = "Aurora" if (rds and rds.get("type") == "aurora") else "RDS"
    rds_id    = rds.get("id") if rds else ""
    rds_label = rds_title + (f"\\n{rds_id}" if rds_id else "")

    ddb_label = ddb or "DynamoDB"

    m = f"""
flowchart LR
  U[User] --> R53[Route 53] --> CF[{cf_label}]
  CF -->|static| S3[{s3label}]
  CF -->|dynamic| GW[{gw_label}]
  GW -->|443/TLS| NLB[{lb_label}]
  subgraph EKS[{eks_label}]
    ING[Ingress] --> BE[Backend Service]
    BE -- OIDC/SAML --> KC[{keycloak}]
  end
  NLB -->|ingress| ING
  BE -->|authorized (FIS)| RDS[{rds_label}]
  BE -.->|external/unauth| DDB[{ddb_label}]
  BE -->|read/write| S3
"""
    (OUTDIR / path).write_text("```mermaid\n" + m.strip() + "\n```")







--------------
GRAPH_ATTR = dict(rankdir="LR", splines="ortho", nodesep="1.1", ranksep="1.2", pad="0.2", concentrate="false")
NODE_ATTR  = dict(fontname="Helvetica", fontsize="12", margin="0.06,0.04")
EDGE_ATTR  = dict(arrowsize="0.9", penwidth="1.2", labelfontsize="10", tailclip="true", headclip="true")

with Diagram("Ethos Portal ‚Äì Context & Containers",
             filename=str(OUTDIR/"01_context_container"),
             show=False, outformat="svg",         # SVG = crisp + editable
             graph_attr=GRAPH_ATTR, node_attr=NODE_ATTR, edge_attr=EDGE_ATTR):

    # ‚Ä¶
    cf_i >> Edge(label="dynamic", minlen="2") >> gw_i \
        >> Edge(label="443/TLS", minlen="2") >> nlb_i \
        >> Edge(label="ingress", minlen="2") >> ingress

    # Add an invisible ‚Äúknee‚Äù if a line crosses an icon:
    from diagrams.custom import Custom
    SPACER = "data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1' height='1'/>"
    elbow = Custom("", SPACER)   # 1x1 transparent node

    backend >> Edge(minlen="2") >> elbow >> Edge(minlen="2") >> rds_i


----

def emit_mermaid_context(path):
    cf = cf_summary(); gw = apigw_v2_summary(); lb = nlb_summary(); eks = eks_summary()
    rds = rds_pick(); ddb = ddb_pick()
    keycloak = detect_keycloak_name()
    s3label = "S3 (static/state)"
    m = f"""
flowchart LR
  U[User] --> R53[Route 53] --> CF[CloudFront\\n{(cf or {}).get('id','')}]
  CF -->|static| S3[{s3label}]
  CF -->|dynamic| GW[API Gateway\\n{(gw or {}).get('id','')}]
  GW -->|443/TLS| NLB[NLB\\n{(lb or {}).get('name','')}]
  subgraph EKS[{(eks or {}).get('name','')}]
    ING[Ingress] --> BE[Backend Service]
    BE -- OIDC/SAML --> KC[{keycloak}]
  end
  NLB -->|ingress| ING
  BE -->|authorized (FIS)| RDS[{('Aurora' if (rds and rds['type']=='aurora') else 'RDS') + '\\n' + (rds['id'] if rds else '')}]
  BE -.->|external/unauth| DDB[{ddb or 'DynamoDB'}]
  BE -->|read/write| S3
"""
    (OUTDIR / path).write_text("```mermaid\n" + m.strip() + "\n```")

# call it:
emit_mermaid_context("01_context_container.mmd")













------------------------------------------------------------------------------------------
#!/usr/bin/env python3
"""
Ethos Portal ‚Äì diagram generator (SVG) from AWS CLI JSON exports.

Outputs (to ./diagrams):
  - 01_context_container.svg                 (clean context & containers)
  - 01b_context_container_network.svg        (context + AWS/VPC/Subnets/AZ frame)
  - 02_request_path.svg                      (API request path)
  - 03_topology.svg                          (compact VPC topology)

Author: you + ChatGPT
"""

import json
import pathlib
import re
from contextlib import suppress

# diagrams (mingrammer)
from diagrams import Diagram, Cluster, Edge
from diagrams.aws.network import (
    Route53, CloudFront, APIGateway, ELB,
    InternetGateway, PrivateSubnet, PublicSubnet
)
from diagrams.aws.compute import EKS, Lambda
from diagrams.aws.storage import S3
from diagrams.aws.database import RDS as RDSIcon, Aurora, Dynamodb
from diagrams.aws.security import SecretsManager

# Optional VPC Endpoint icon (not in all versions of diagrams)
try:
    from diagrams.aws.network import VPCEndpointInterface as VPCEndpointIcon
except Exception:
    VPCEndpointIcon = None

# ----------------------------- config & helpers -----------------------------

EXPORTS = pathlib.Path("as-is/exports")
OUTDIR = pathlib.Path("diagrams")
OUTDIR.mkdir(exist_ok=True, parents=True)

# Graphviz polish
GRAPH_ATTR = dict(rankdir="LR", splines="ortho", nodesep="1.0", ranksep="1.2", pad="0.2")
NODE_ATTR = dict(fontname="Helvetica", fontsize="12", margin="0.05,0.03")
EDGE_ATTR = dict(arrowsize="0.8", penwidth="1.2")

def load_json(name):
    p = EXPORTS / name
    if not p.exists():
        return None
    with open(p) as f:
        return json.load(f)

def first(lst, default=None):
    return lst[0] if lst else default

def find_first_file(glob_pattern: str):
    files = sorted(EXPORTS.glob(glob_pattern))
    return files[0] if files else None

# ----------------------------- light parsers -----------------------------

def cf_summary():
    lst = (load_json("cf_distributions.json") or {}).get("DistributionList", {}).get("Items", [])
    if not lst:
        return None
    did = lst[0]["Id"]
    conf = (load_json(f"cf_{did}.json") or {}).get("Distribution", {}).get("DistributionConfig", {})
    aliases = conf.get("Aliases", {}).get("Items", []) or []
    return {"id": did, "aliases": aliases}

def apigw_v2_summary():
    items = (load_json("apigw_v2_apis.json") or {}).get("Items", [])
    if not items:
        return None
    api = items[0]
    api_id = api.get("ApiId")
    name = api.get("Name")
    integ = load_json(f"apigw_v2_{api_id}_integrations.json")
    nlb_links = []
    if integ and "Items" in integ:
        for it in integ["Items"]:
            uri = (it.get("IntegrationUri") or it.get("IntegrationUriArn") or "")
            if "elasticloadbalancing" in uri:
                nlb_links.append(uri)
    return {"id": api_id, "name": name, "nlb_links": nlb_links}

def nlb_summary():
    nlbs = load_json("elbv2_nlbs.json") or []
    if not nlbs:
        lbs = (load_json("elbv2_lbs.json") or {}).get("LoadBalancers", [])
        nlbs = [lb for lb in lbs if lb.get("Type") == "network"]
    if not nlbs:
        return None
    lb = nlbs[0]
    # Try to find its listeners (from export files like elbv2_<LBID>_listeners.json)
    listeners_file = find_first_file("elbv2_*_listeners.json")
    port_label = ""
    if listeners_file:
        try:
            j = json.load(open(listeners_file))
            ports = [str(li.get("Port")) for li in j.get("Listeners", []) if li.get("Port")]
            if ports:
                port_label = f" :{','.join(sorted(set(ports)))}"
        except Exception:
            pass
    return {
        "name": lb.get("LoadBalancerName"),
        "dns": lb.get("DNSName"),
        "port_label": port_label,
        "vpc": lb.get("VpcId"),
    }

def eks_summary():
    names = (load_json("eks_clusters.json") or {}).get("clusters", [])
    if not names:
        return None
    return {"name": names[0]}

def detect_keycloak_name():
    for fname in EXPORTS.glob("eks_*_deploys.yaml"):
        try:
            txt = open(fname).read().lower()
            m = re.search(r'name:\s*keycloak[^\n]*', txt)
            if m:
                return "Keycloak (EKS)"
        except Exception:
            pass
    return "Keycloak"

def rds_pick():
    clusters = (load_json("rds_clusters.json") or {}).get("DBClusters", [])
    insts = (load_json("rds_instances.json") or {}).get("DBInstances", [])
    pickc = first([c for c in clusters if re.search(r'ethos|portal|keycloak', c.get("DBClusterIdentifier",""), re.I)], default=first(clusters))
    if pickc:
        return {"type": "aurora", "id": pickc.get("DBClusterIdentifier")}
    picki = first([i for i in insts if re.search(r'ethos|portal|keycloak', i.get("DBInstanceIdentifier",""), re.I)], default=first(insts))
    if picki:
        return {"type": "rds", "id": picki.get("DBInstanceIdentifier")}
    return None

def ddb_pick():
    names = (load_json("ddb_tables.json") or {}).get("TableNames", [])
    return first([n for n in names if re.search(r'ethos|portal', n, re.I)], default=first(names))

def secrets_summary():
    secrets = (load_json("secrets_list.json") or {}).get("SecretList", [])
    picks = [s for s in secrets if re.search(r'ethos|portal|eks|keycloak', (s.get("Name") or ""), re.I)]
    picks = picks or secrets[:1]
    return [s.get("Name") for s in picks[:2]] if picks else []

def pick_vpc():
    vpcs = load_json("vpcs.json") or {}
    return first(vpcs.get("Vpcs", []), default={"VpcId": "vpc-unknown"})

def list_subnets(vpc_id):
    subnets = (load_json("subnets.json") or {}).get("Subnets", [])
    subs = [s for s in subnets if s.get("VpcId") == vpc_id]
    pubs = [s for s in subs if s.get("MapPublicIpOnLaunch")]
    pris = [s for s in subs if not s.get("MapPublicIpOnLaunch")]
    def by_az(xs):
        d = {}
        for s in xs:
            d.setdefault(s.get("AvailabilityZone", "AZ-?"), []).append(s)
        return d
    return by_az(pubs), by_az(pris)

# ----------------------------- tiny layout helper -----------------------------

from diagrams.custom import Custom
SPACER_ICON = "data:image/svg+xml;utf8,<svg xmlns='http://www.w3.org/2000/svg' width='1' height='1'/>"
def spacer(label=""):
    """A 1x1 transparent node that forces neat elbows when needed."""
    return Custom(label, SPACER_ICON)

# ----------------------------- diagram 1 (clean) -----------------------------

def draw_context_container_clean():
    cf = cf_summary(); gw = apigw_v2_summary(); lb = nlb_summary(); eks = eks_summary()
    rds = rds_pick(); ddb = ddb_pick(); secrets = secrets_summary()
    keycloak_name = detect_keycloak_name()

    with Diagram("Ethos Portal ‚Äì Context & Containers",
                 filename=str(OUTDIR/"01_context_container"),
                 show=False, outformat="svg",
                 graph_attr=GRAPH_ATTR, node_attr=NODE_ATTR, edge_attr=EDGE_ATTR):

        # Edge & CDN
        user = Route53("User")
        r53 = Route53("Route 53")
        cf_i = CloudFront(f"CloudFront\n{(cf or {}).get('id','')}")
        gw_i = APIGateway(f"API Gateway\n{(gw or {}).get('id','')}")
        nlb_i = ELB(f"NLB{(lb or {}).get('port_label','')}\n{(lb or {}).get('name','')}")
        s3_i = S3("S3 (static/state)")
        lam_i = Lambda(first((load_json("lambda_functions.json") or {}).get("Functions", []), {"FunctionName":"Lambda"})["FunctionName"])

        # EKS cluster & app containers
        with Cluster(f"EKS {(eks or {}).get('name','')}"):
            ingress = EKS("Ingress")
            backend = EKS("Backend Service")
            keycloak = EKS(keycloak_name)

        # Data stores & secrets
        if rds and rds["type"] == "aurora":
            rds_i = Aurora(f"Aurora\n{rds['id']}")
        elif rds:
            rds_i = RDSIcon(f"RDS\n{rds['id']}")
        else:
            rds_i = RDSIcon("RDS")

        ddb_i = Dynamodb(ddb or "DynamoDB")
        secnodes = [SecretsManager(n) for n in (secrets or ["Secrets Manager"])]

        # Flow
        user >> Edge(label="HTTPS", minlen="2") >> r53 >> Edge(label="Alias", minlen="2") >> cf_i
        cf_i  >> Edge(label="static", minlen="2") >> s3_i
        cf_i  >> Edge(label="dynamic", minlen="2") >> gw_i \
              >> Edge(label="443/TLS", minlen="2") >> nlb_i \
              >> Edge(label="ingress", minlen="2") >> ingress >> backend

        # Auth & storage decisions
        elbow = spacer()  # neat elbow for RDS branch
        backend << Edge(label="OIDC/SAML", minlen="2") >> keycloak
        backend >> Edge(label="authorized (FIS)", minlen="2") >> elbow >> Edge(minlen="2") >> rds_i
        backend >> Edge(style="dashed", label="external/unauth", minlen="2") >> ddb_i

        # Events & secrets use
        backend >> Edge(label="read/write", minlen="2") >> s3_i
        s3_i >> Edge(label="event", minlen="2") >> lam_i
        for s in secnodes:
            backend >> Edge(style="dotted", label="IRSA", minlen="2") >> s

# ----------------------------- diagram 1b (with AWS/VPC/AZ frame) -----------------------------

def draw_context_container_with_network_frame():
    cf = cf_summary(); gw = apigw_v2_summary(); lb = nlb_summary(); eks = eks_summary()
    rds = rds_pick(); ddb = ddb_pick(); secrets = secrets_summary()
    keycloak_name = detect_keycloak_name()

    vpc_id = pick_vpc().get("VpcId", "vpc-unknown")
    pubs_by_az, pris_by_az = list_subnets(vpc_id)

    with Diagram("Ethos Portal ‚Äì Context & Containers (with AWS/VPC frame)",
                 filename=str(OUTDIR/"01b_context_container_network"),
                 show=False, outformat="svg",
                 graph_attr=GRAPH_ATTR, node_attr=NODE_ATTR, edge_attr=EDGE_ATTR):

        user = Route53("User")
        r53 = Route53("Route 53")

        with Cluster("AWS Account"):
            with Cluster(f"VPC {vpc_id}"):
                # AZ clusters (two max for clarity)
                az_names = sorted(set(list(pubs_by_az.keys()) + list(pris_by_az.keys())))[:2]
                az_nodes = []
                for az in az_names:
                    with Cluster(f"{az}"):
                        pub = PublicSubnet("public")
                        pri = PrivateSubnet("private")
                        az_nodes.append((pub, pri))

                cf_i = CloudFront(f"CloudFront\n{(cf or {}).get('id','')}")
                gw_i = APIGateway(f"API Gateway\n{(gw or {}).get('id','')}")
                nlb_i = ELB(f"NLB{(lb or {}).get('port_label','')}\n{(lb or {}).get('name','')}")
                s3_i = S3("S3 (static/state)")
                lam_i = Lambda(first((load_json("lambda_functions.json") or {}).get("Functions", []), {"FunctionName":"Lambda"})["FunctionName"])

                with Cluster(f"EKS {(eks or {}).get('name','')}"):
                    ingress = EKS("Ingress")
                    backend = EKS("Backend Service")
                    keycloak = EKS(keycloak_name)

                # Data stores & secrets
                if rds and rds["type"] == "aurora":
                    rds_i = Aurora(f"Aurora\n{rds['id']}")
                elif rds:
                    rds_i = RDSIcon(f"RDS\n{rds['id']}")
                else:
                    rds_i = RDSIcon("RDS")

                ddb_i = Dynamodb(ddb or "DynamoDB")
                secnodes = [SecretsManager(n) for n in (secrets or ["Secrets Manager"])]

        # Edges across frame
        user >> Edge(label="HTTPS", minlen="2") >> r53 >> Edge(label="Alias", minlen="2") >> cf_i
        cf_i  >> Edge(label="static", minlen="2") >> s3_i
        cf_i  >> Edge(label="dynamic", minlen="2") >> gw_i \
              >> Edge(label="443/TLS", minlen="2") >> nlb_i \
              >> Edge(label="ingress", minlen="2") >> ingress >> backend

        backend << Edge(label="OIDC/SAML", minlen="2") >> keycloak
        backend >> Edge(label="authorized (FIS)", minlen="2") >> rds_i
        backend >> Edge(style="dashed", label="external/unauth", minlen="2") >> ddb_i
        backend >> Edge(label="read/write", minlen="2") >> s3_i
        s3_i >> Edge(label="event", minlen="2") >> lam_i
        for s in secnodes:
            backend >> Edge(style="dotted", label="IRSA", minlen="2") >> s

# ----------------------------- diagram 2 (request path) -----------------------------

def draw_request_path():
    cf = cf_summary(); gw = apigw_v2_summary(); lb = nlb_summary(); eks = eks_summary()

    with Diagram("Ethos Portal ‚Äì API Request Path",
                 filename=str(OUTDIR/"02_request_path"),
                 show=False, outformat="svg",
                 graph_attr=GRAPH_ATTR, node_attr=NODE_ATTR, edge_attr=EDGE_ATTR):

        user = Route53("Browser")
        r53 = Route53("Route 53")
        cf_i = CloudFront(f"CloudFront\n{(cf or {}).get('id','')}")
        gw_i = APIGateway(f"API GW\n{(gw or {}).get('id','')}")
        lb_i = ELB(f"NLB{(lb or {}).get('port_label','')}\n{(lb or {}).get('name','')}")

        with Cluster(f"EKS {(eks or {}).get('name','')}"):
            ingress = EKS("Ingress")
            svc = EKS("Backend")
            keycloak = EKS("Keycloak")

        user >> Edge(label="HTTPS", minlen="2") >> r53 >> Edge(label="Alias", minlen="2") >> cf_i
        cf_i >> Edge(label="HTTPS", minlen="2") >> gw_i \
             >> Edge(label="TLS 443", minlen="2") >> lb_i \
             >> Edge(label="TCP 443", minlen="2") >> ingress >> svc
        svc << Edge(label="OIDC", minlen="2") >> keycloak

# ----------------------------- diagram 3 (topology schematic) -----------------------------

def draw_topology_schematic():
    vpc_id = pick_vpc().get("VpcId", "vpc-unknown")
    pubs_by_az, pris_by_az = list_subnets(vpc_id)

    with Diagram(f"Ethos Portal ‚Äì VPC Topology (schematic)",
                 filename=str(OUTDIR/"03_topology"),
                 show=False, outformat="svg",
                 graph_attr=GRAPH_ATTR, node_attr=NODE_ATTR, edge_attr=EDGE_ATTR):

        igw = InternetGateway("IGW")

        with Cluster(f"VPC {vpc_id}"):
            # two AZs for readability
            az_names = sorted(set(list(pubs_by_az.keys()) + list(pris_by_az.keys())))[:2]

            per_az = []
            for az in az_names:
                with Cluster(az):
                    pub = PublicSubnet("public")
                    pri = PrivateSubnet("private")
                    nlb_eni = ELB("NLB ENI")
                    per_az.append((pub, pri, nlb_eni))

            s3e = VPCEndpointIcon("S3 Endpoint") if VPCEndpointIcon else ELB("S3 Endpoint")

        # Wiring
        with suppress(Exception):
            if per_az:
                igw >> per_az[0][0]
                if len(per_az) > 1:
                    igw >> per_az[1][0]
        for (_, pri, nlb_eni) in per_az:
            nlb_eni - pri
            s3e - pri

# ----------------------------- entrypoint -----------------------------

if __name__ == "__main__":
    draw_context_container_clean()
    draw_context_container_with_network_frame()
    draw_request_path()
    draw_topology_schematic()
    print(f"SVGs written to {OUTDIR.resolve()}")








-------------------------------------------------------------------------------------------------------------------------------------------
#!/usr/bin/env bash
set -euo pipefail

# === Config ===
OUT="${OUT:-as-is/exports}"                 # override with OUT=/path ./export_data_tier.sh
REGION="${AWS_REGION:-${REGION:-eu-west-1}}"# override with REGION=us-east-1 ./export_data_tier.sh
FILTER_NAME="${FILTER_NAME:-}"              # optional: grep filter for names/ids (e.g., ethos|portal|keycloak)

mkdir -p "$OUT"
echo "Exporting data-tier metadata to $OUT (region: $REGION)"
have_jq() { command -v jq >/dev/null 2>&1; }

# ---------- RDS / Aurora ----------
aws rds describe-db-instances --region "$REGION" > "$OUT/rds_instances.json"
aws rds describe-db-clusters  --region "$REGION" > "$OUT/rds_clusters.json"

if have_jq; then
  echo "Tagging RDS instances‚Ä¶"
  jq -r '.DBInstances[].DBInstanceArn' "$OUT/rds_instances.json" 2>/dev/null \
    | { if [ -n "$FILTER_NAME" ]; then grep -Ei "$FILTER_NAME" || true; else cat; fi; } \
    | while read -r ARN; do
        safe="$(echo "$ARN" | sed 's#.*:db:##')"
        aws rds list-tags-for-resource --resource-name "$ARN" --region "$REGION" > "$OUT/rds_tags_${safe}.json" || true
      done

  echo "Tagging RDS clusters‚Ä¶"
  jq -r '.DBClusters[].DBClusterArn' "$OUT/rds_clusters.json" 2>/dev/null \
    | { if [ -n "$FILTER_NAME" ]; then grep -Ei "$FILTER_NAME" || true; else cat; fi; } \
    | while read -r ARN; do
        safe="$(echo "$ARN" | sed 's#.*:cluster:##')"
        aws rds list-tags-for-resource --resource-name "$ARN" --region "$REGION" > "$OUT/rds_cluster_tags_${safe}.json" || true
      done
else
  echo "jq not found; skipping per-resource tag exports." >&2
fi

# ---------- DynamoDB ----------
aws dynamodb list-tables --region "$REGION" > "$OUT/ddb_tables.json"
if have_jq; then
  jq -r '.TableNames[]' "$OUT/ddb_tables.json" 2>/dev/null \
    | { if [ -n "$FILTER_NAME" ]; then grep -Ei "$FILTER_NAME" || true; else cat; fi; } \
    | while read -r T; do
        aws dynamodb describe-table --table-name "$T" --region "$REGION" > "$OUT/ddb_${T}.json" || true
      done
else
  echo "jq not found; export contains list only (no per-table describe)." >&2
fi

# ---------- Secrets Manager (metadata only) ----------
aws secretsmanager list-secrets --region "$REGION" > "$OUT/secrets_list.json"
if have_jq; then
  jq -r '.SecretList[].ARN' "$OUT/secrets_list.json" 2>/dev/null \
    | { if [ -n "$FILTER_NAME" ]; then grep -Ei "$FILTER_NAME" || true; else cat; fi; } \
    | while read -r SARN; do
        base="$(basename "$SARN")"
        aws secretsmanager get-resource-policy --secret-id "$SARN" --region "$REGION" > "$OUT/secret_policy_${base}.json" 2>/dev/null || true
      done
fi

echo "Done."



--------
# ----- RDS / Aurora -----
aws rds describe-db-instances --region "$REGION" > "$OUT/rds_instances.json"
aws rds describe-db-clusters  --region "$REGION" > "$OUT/rds_clusters.json"
# (optional) tags for identification
jq -r '.DBInstances[].DBInstanceArn' "$OUT/rds_instances.json" 2>/dev/null | while read -r ARN; do
  aws rds list-tags-for-resource --resource-name "$ARN" --region "$REGION" > "$OUT/rds_tags_$(echo "$ARN" | sed 's#.*:db:##').json" || true
done
jq -r '.DBClusters[].DBClusterArn' "$OUT/rds_clusters.json" 2>/dev/null | while read -r ARN; do
  aws rds list-tags-for-resource --resource-name "$ARN" --region "$REGION" > "$OUT/rds_cluster_tags_$(echo "$ARN" | sed 's#.*:cluster:##').json" || true
done

# ----- DynamoDB -----
aws dynamodb list-tables --region "$REGION" > "$OUT/ddb_tables.json"
jq -r '.TableNames[]' "$OUT/ddb_tables.json" 2>/dev/null | while read -r T; do
  aws dynamodb describe-table --table-name "$T" --region "$REGION" > "$OUT/ddb_${T}.json" || true
done

# ----- Secrets Manager (metadata only) -----
aws secretsmanager list-secrets --region "$REGION" > "$OUT/secrets_list.json"
# (optional) resource policies for posture evidence
jq -r '.SecretList[].ARN' "$OUT/secrets_list.json" 2>/dev/null | while read -r SARN; do
  aws secretsmanager get-resource-policy --secret-id "$SARN" --region "$REGION" > "$OUT/secret_policy_$(basename "$SARN").json" 2>/dev/null || true
done


---------

#!/usr/bin/env python3
import json, os, pathlib, re
from contextlib import suppress

# diagrams
from diagrams import Diagram, Cluster, Edge
from diagrams.aws.network import Route53, CloudFront, APIGateway, ELB, InternetGateway, PrivateSubnet, PublicSubnet
from diagrams.aws.compute import EKS, Lambda
from diagrams.aws.storage import S3
from diagrams.aws.database import RDS as RDSIcon, Aurora, Dynamodb
from diagrams.aws.security import SecretsManager

# Optional endpoint icon (not present in all versions)
try:
    from diagrams.aws.network import VPCEndpointInterface as VPCEndpointIcon
except Exception:
    VPCEndpointIcon = None

EXPORTS = pathlib.Path("as-is/exports")
OUTDIR  = pathlib.Path("diagrams")
OUTDIR.mkdir(exist_ok=True, parents=True)

def load_json(name):
    p = EXPORTS / name
    if not p.exists(): return None
    with open(p) as f: return json.load(f)

def first(lst, default=None):
    return lst[0] if lst else default

# ---------- Parsers ----------
def cf_summary():
    lst = (load_json("cf_distributions.json") or {}).get("DistributionList", {}).get("Items", [])
    if not lst: return None
    did = lst[0]["Id"]
    conf = (load_json(f"cf_{did}.json") or {}).get("Distribution", {}).get("DistributionConfig", {})
    aliases = conf.get("Aliases", {}).get("Items", []) or []
    return {"id": did, "aliases": aliases}

def apigw_v2_summary():
    items = (load_json("apigw_v2_apis.json") or {}).get("Items", [])
    if not items: return None
    api = items[0]; api_id = api.get("ApiId"); name = api.get("Name")
    integ = load_json(f"apigw_v2_{api_id}_integrations.json")
    nlb_links = []
    if integ and "Items" in integ:
        for it in integ["Items"]:
            uri = (it.get("IntegrationUri") or it.get("IntegrationUriArn") or "")
            if "elasticloadbalancing" in uri:
                nlb_links.append(uri)
    return {"id": api_id, "name": name, "nlb_links": nlb_links}

def nlb_summary():
    nlbs = load_json("elbv2_nlbs.json") or []
    if not nlbs:
        lbs = (load_json("elbv2_lbs.json") or {}).get("LoadBalancers", [])
        nlbs = [lb for lb in lbs if lb.get("Type") == "network"]
    if not nlbs: return None
    lb = nlbs[0]
    return {"name": lb.get("LoadBalancerName"), "dns": lb.get("DNSName")}

def eks_summary():
    names = (load_json("eks_clusters.json") or {}).get("clusters", [])
    if not names: return None
    return {"name": names[0]}

def detect_keycloak_name():
    # Look for 'keycloak' in k8s exports; fall back to generic
    for fname in EXPORTS.glob("eks_*_deploys.yaml"):
        try:
            txt = open(fname).read().lower()
            m = re.search(r'name:\s*keycloak[^\n]*', txt)
            if m: return "Keycloak (EKS)"
        except Exception:
            pass
    return "Keycloak"

def rds_pick():
    # Prefer clusters (Aurora) else instances; pick one matching 'ethos' if possible
    clusters = (load_json("rds_clusters.json") or {}).get("DBClusters", [])
    insts    = (load_json("rds_instances.json") or {}).get("DBInstances", [])
    pick = first([c for c in clusters if re.search(r'ethos|portal|keycloak', c.get("DBClusterIdentifier",""), re.I)], default=first(clusters))
    if pick:
        return {"type": "aurora", "id": pick.get("DBClusterIdentifier")}
    picki = first([i for i in insts if re.search(r'ethos|portal|keycloak', i.get("DBInstanceIdentifier",""), re.I)], default=first(insts))
    if picki:
        return {"type": "rds", "id": picki.get("DBInstanceIdentifier")}
    return None

def ddb_pick():
    names = (load_json("ddb_tables.json") or {}).get("TableNames", [])
    pick = first([n for n in names if re.search(r'ethos|portal', n, re.I)], default=first(names))
    return pick

def secrets_summary():
    secrets = (load_json("secrets_list.json") or {}).get("SecretList", [])
    # Only show 1-2 to keep diagram clean
    picks = [s for s in secrets if re.search(r'ethos|portal|eks|keycloak', (s.get("Name") or ""), re.I)]
    picks = picks or secrets[:1]
    return [s.get("Name") for s in picks[:2]]

# ---------- Diagrams ----------
GRAPH_STYLE = dict(
    rankdir="LR", splines="ortho", nodesep="1", ranksep="1.1", fontname="Helvetica", fontsize="12"
)

def draw_context_container():
    cf = cf_summary(); gw = apigw_v2_summary(); lb = nlb_summary(); eks = eks_summary()
    s3label = "S3 (static/state)"
    lambdas = (load_json("lambda_functions.json") or {}).get("Functions", [])
    lam = first([x["FunctionName"] for x in lambdas], "Lambda")

    rds = rds_pick()
    ddb = ddb_pick()
    secrets = secrets_summary()
    keycloak_name = detect_keycloak_name()

    with Diagram("Ethos Portal ‚Äì Context & Containers", filename=str(OUTDIR/"01_context_container"),
                 show=False, outformat="png", graph_attr=GRAPH_STYLE):
        # Edge & CDN
        user = Route53("User")
        r53  = Route53("Route 53")
        cf_i = CloudFront(f"CloudFront\n{(cf or {}).get('id','')}")
        gw_i = APIGateway(f"API Gateway\n{(gw or {}).get('id','')}")
        nlb_i = ELB(f"NLB\n{(lb or {}).get('name','')}")
        s3_i = S3(s3label)
        lam_i = Lambda(lam)

        # EKS cluster & app containers
        with Cluster(f"EKS {(eks or {}).get('name','')}"):
            ingress = EKS("Ingress")
            backend = EKS("Backend Service")
            keycloak = EKS(keycloak_name)

        # Data stores & secrets
        if rds and rds["type"] == "aurora":
            rds_i = Aurora(f"Aurora\n{rds['id']}")
        elif rds:
            rds_i = RDSIcon(f"RDS\n{rds['id']}")
        else:
            rds_i = RDSIcon("RDS")

        ddb_i = Dynamodb(ddb or "DynamoDB")
        secnodes = [SecretsManager(n) for n in (secrets or ["Secrets Manager"])]

        # Flow
        user >> r53 >> cf_i
        cf_i >> Edge(label="static") >> s3_i
        cf_i >> Edge(label="dynamic") >> gw_i >> Edge(label="443/TLS") >> nlb_i >> Edge(label="ingress") >> ingress >> backend

        # Auth & storage decisions
        backend << Edge(label="OIDC/SAML") >> keycloak
        backend >> Edge(label="authorized (FIS)") >> rds_i
        backend >> Edge(style="dashed", label="external/unauth") >> ddb_i

        # Events & secrets use
        backend >> Edge(label="read/write") >> s3_i
        s3_i >> Edge(label="event") >> lam_i
        for s in secnodes:
            backend >> Edge(style="dotted", label="IRSA") >> s

def draw_request_path():
    cf = cf_summary(); gw = apigw_v2_summary(); lb = nlb_summary(); eks = eks_summary()
    with Diagram("Ethos Portal ‚Äì API Request Path", filename=str(OUTDIR/"02_request_path"),
                 show=False, outformat="png", graph_attr=GRAPH_STYLE):
        user = Route53("Browser")
        r53  = Route53("Route 53")
        cf_i = CloudFront(f"CloudFront\n{(cf or {}).get('id','')}")
        gw_i = APIGateway(f"API GW\n{(gw or {}).get('id','')}")
        lb_i = ELB(f"NLB\n{(lb or {}).get('name','')}")
        with Cluster(f"EKS {(eks or {}).get('name','')}"):
            ingress = EKS("Ingress")
            svc     = EKS("Backend")
            keycloak = EKS("Keycloak")

        user >> Edge(label="HTTPS") >> r53 >> Edge(label="Alias") >> cf_i
        cf_i  >> Edge(label="HTTPS") >> gw_i >> Edge(label="TLS 443") >> lb_i >> Edge(label="TCP 443") >> ingress >> svc
        svc   << Edge(label="OIDC") >> keycloak

def draw_topology():
    with Diagram("Ethos Portal ‚Äì VPC Topology (schematic)", filename=str(OUTDIR/"03_topology"),
                 show=False, outformat="png", graph_attr=GRAPH_STYLE):
        igw = InternetGateway("IGW")
        with Cluster("VPC (Ethos Portal)"):
            with Cluster("AZ-a"):
                pub_a = PublicSubnet("public-a")
                pri_a = PrivateSubnet("private-a")
                nlb_a = ELB("NLB ENI-a")

            with Cluster("AZ-b"):
                pub_b = PublicSubnet("public-b")
                pri_b = PrivateSubnet("private-b")
                nlb_b = ELB("NLB ENI-b")

            s3e = VPCEndpointIcon("S3 Endpoint") if VPCEndpointIcon else ELB("S3 Endpoint")

        igw >> pub_a
        igw >> pub_b
        nlb_a - pri_a; nlb_b - pri_b
        s3e - pri_a;   s3e - pri_b

if __name__ == "__main__":
    draw_context_container()
    draw_request_path()
    draw_topology()
    print(f"Wrote diagrams to {OUTDIR.resolve()}")

















----------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------
# macOS (Homebrew) / Linux
brew install graphviz || sudo apt-get install -y graphviz
python3 -m venv venv && source venv/bin/activate
pip install diagrams pyyaml

---------

#!/usr/bin/env python3
import json, os, pathlib, re
from contextlib import suppress

# diagrams (mingrammer)
from diagrams import Diagram, Cluster, Edge
from diagrams.aws.network import Route53, CloudFront, APIGateway, ELB, VPC, InternetGateway, VPCEndpoint
from diagrams.aws.network import PrivateSubnet, PublicSubnet
from diagrams.aws.compute import EKS, Lambda
from diagrams.aws.storage import S3

EXPORTS = pathlib.Path("as-is/exports")
OUTDIR  = pathlib.Path("diagrams")
OUTDIR.mkdir(exist_ok=True, parents=True)

def load_json(path):
    p = EXPORTS / path
    if not p.exists(): return None
    with open(p) as f:
        return json.load(f)

def first(items, key=None, default=None):
    if not items: return default
    return items[0] if key is None else next((i for i in items if key(i)), default)

# ---------- Parsers (best-effort) ----------
def pick_vpc():
    vpcs = load_json("vpcs.json") or {}
    arr = vpcs.get("Vpcs", [])
    return first(arr, default={"VpcId": "vpc-unknown"})

def list_subnets(vpc_id):
    subnets = (load_json("subnets.json") or {}).get("Subnets", [])
    # Filter by VPC
    subs = [s for s in subnets if s.get("VpcId")==vpc_id]
    # Decide public vs private: MapPublicIpOnLaunch is a decent heuristic
    pubs = [s for s in subs if s.get("MapPublicIpOnLaunch")]
    pris = [s for s in subs if not s.get("MapPublicIpOnLaunch")]
    # group by AZ (up to 2 for aesthetics)
    def by_az(xs): 
        d={}
        for s in xs:
            d.setdefault(s["AvailabilityZone"], []).append(s)
        return d
    return by_az(pubs), by_az(pris)

def cf_summary():
    dist = load_json("cf_distributions.json") or {}
    items = dist.get("DistributionList", {}).get("Items", [])
    if not items: 
        return None
    did = items[0]["Id"]
    full = load_json(f"cf_{did}.json") or {}
    conf = full.get("Distribution", {}).get("DistributionConfig", {})
    origins = [o.get("DomainName") for o in conf.get("Origins", {}).get("Items", [])]
    aliases = conf.get("Aliases", {}).get("Items", [])
    return {"id": did, "origins": origins, "aliases": aliases}

def apigw_v2_summary():
    apis = load_json("apigw_v2_apis.json") or {}
    items = apis.get("Items", [])
    if not items: return None
    api = items[0]
    api_id = api.get("ApiId"); name = api.get("Name")
    # Try to find integration to ELB/NLB
    integ = load_json(f"apigw_v2_{api_id}_integrations.json")
    tgts = []
    if integ and "Items" in integ:
        for it in integ["Items"]:
            uri = (it.get("IntegrationUri") or it.get("IntegrationUriArn") or "")
            if "elasticloadbalancing" in uri:
                tgts.append(uri)
    return {"id": api_id, "name": name, "nlb_links": tgts}

def nlb_summary():
    nlbs = load_json("elbv2_nlbs.json") or []
    if not nlbs: 
        # fallback: filter from full LB list
        lbs = (load_json("elbv2_lbs.json") or {}).get("LoadBalancers", [])
        nlbs = [lb for lb in lbs if lb.get("Type") == "network"]
    if not nlbs: 
        return None
    lb = nlbs[0]
    return {
        "arn": lb.get("LoadBalancerArn"),
        "name": lb.get("LoadBalancerName"),
        "dns": lb.get("DNSName"),
        "vpc": lb.get("VpcId"),
        "scheme": lb.get("Scheme"),
        "azs": [z.get("ZoneName") for z in lb.get("AvailabilityZones", [])],
    }

def eks_summary():
    cl = load_json("eks_clusters.json") or {}
    names = cl.get("clusters", [])
    if not names: return None
    name = names[0]
    desc = load_json(f"eks_{name}.json") or {}
    ver  = desc.get("cluster", {}).get("version")
    return {"name": name, "version": ver}

def s3_brief():
    b = load_json("s3_buckets.json") or {}
    names = [x["Name"] for x in b.get("Buckets", [])]
    return names[:3]  # keep the diagram clean

def lambda_brief():
    f = load_json("lambda_functions.json") or {}
    items = f.get("Functions", [])
    return [x.get("FunctionName") for x in items[:2]]  # max two icons on diagram

# ---------- Diagram 1: Context/Container ----------
def draw_context_container():
    cf = cf_summary()
    apigw = apigw_v2_summary()
    nlb = nlb_summary()
    eks = eks_summary()
    s3s = s3_brief()
    lambdas = lambda_brief()

    title = "Ethos Portal ‚Äì Context & Containers"
    filename = str(OUTDIR / "01_context_container")

    with Diagram(title, filename=filename, show=False, outformat="png"):
        user = Route53("User via DNS")  # Just to keep icon variety; we‚Äôll add real R53 next line
        r53  = Route53("Route 53")
        cf_i = CloudFront(f"CloudFront\n{cf['id'] if cf else ''}")
        apigw_i = APIGateway(f"API Gateway\n{apigw['id'] if apigw else ''}")
        nlb_i = ELB(f"NLB\n{(nlb or {}).get('name','')}")
        eks_i = EKS(f"EKS\n{(eks or {}).get('name','')}")
        s3_i  = S3("S3 (static/state)")
        # Keep Lambdas compact
        l_nodes = [Lambda(n) for n in lambdas] if lambdas else [Lambda("Lambda")]

        user >> r53 >> cf_i
        cf_i >> Edge(label="static") >> s3_i
        cf_i >> Edge(label="dynamic") >> apigw_i >> Edge(label="443/TLS") >> nlb_i >> Edge(label="ingress") >> eks_i
        # side paths
        eks_i >> Edge(label="read/write") >> s3_i
        s3_i >> Edge(label="event") >> l_nodes[0]

# ---------- Diagram 2: Request Path (icons w/ arrows) ----------
def draw_request_path():
    cf = cf_summary(); apigw = apigw_v2_summary(); nlb = nlb_summary(); eks = eks_summary()

    title = "Ethos Portal ‚Äì API Request Path"
    filename = str(OUTDIR / "02_request_path")

    with Diagram(title, filename=filename, show=False, outformat="png"):
        user = Route53("Browser")
        r53  = Route53("Route 53")
        cf_i = CloudFront(f"CloudFront\n{cf['id'] if cf else ''}")
        gw   = APIGateway(f"API GW\n{(apigw or {}).get('id','')}")
        lb   = ELB(f"NLB\n{(nlb or {}).get('name','')}")
        ing  = EKS(f"Ingress (EKS)\n{(eks or {}).get('name','')}")

        user >> Edge(label="HTTPS") >> r53 >> Edge(label="Alias") >> cf_i
        cf_i >> Edge(label="HTTPS") >> gw >> Edge(label="TLS 443") >> lb >> Edge(label="TCP 443") >> ing

# ---------- Diagram 3: Network Topology ----------
def draw_topology():
    vpc = pick_vpc().get("VpcId")
    pubs_by_az, pris_by_az = list_subnets(vpc)
    nlb = nlb_summary()

    title = f"Ethos Portal ‚Äì VPC Topology ({vpc})"
    filename = str(OUTDIR / "03_topology")

    with Diagram(title, filename=filename, show=False, outformat="png"):
        igw = InternetGateway("IGW")
        with Cluster(f"VPC {vpc}"):
            # draw at most two AZs to keep legible
            az_names = sorted(set(list(pubs_by_az.keys()) + list(pris_by_az.keys())))[:2]
            az_clusters = []
            for az in az_names:
                with Cluster(f"{az}"):
                    # Public subnets
                    pub_nodes = []
                    for s in pubs_by_az.get(az, [])[:1]:
                        pub_nodes.append(PublicSubnet(f"{s['SubnetId']}"))
                    # Private subnets
                    pri_nodes = []
                    for s in pris_by_az.get(az, [])[:1]:
                        pri_nodes.append(PrivateSubnet(f"{s['SubnetId']}"))
                    # Drop an NLB ENI per AZ (symbolically)
                    nlb_node = ELB(f"NLB ENI\n{(nlb or {}).get('name','')}")
                    az_clusters.append((pub_nodes, pri_nodes, nlb_node))

            # S3 Gateway/Interface Endpoint (symbolic)
            s3e = VPCEndpoint("S3 VPC Endpoint")

        # Connect IGW to first public subnets (if any)
        with suppress(Exception):
            if az_clusters and az_clusters[0][0]:
                igw >> az_clusters[0][0][0]
            if len(az_clusters) > 1 and az_clusters[1][0]:
                igw >> az_clusters[1][0][0]

        # NLB sits in private subnets here (common pattern with Ingress)
        for (_, pri_nodes, nlb_node) in az_clusters:
            if pri_nodes:
                nlb_node - pri_nodes[0]
        # VPC endpoint links
        for (_, pri_nodes, _) in az_clusters:
            if pri_nodes:
                s3e - pri_nodes[0]

# ---------- Run ----------
if __name__ == "__main__":
    draw_context_container()
    draw_request_path()
    draw_topology()
    print(f"Diagrams written to {OUTDIR.resolve()}")




----

python generate_ethos_diagrams.py
# -> diagrams/01_context_container.png
# -> diagrams/02_request_path.png
# -> diagrams/03_topology.png





----------------
#!/usr/bin/env bash
set -euo pipefail

# ===== config =====
OUT="as-is/exports"
REGION="${AWS_REGION:-$(aws configure get region || echo eu-west-1)}"
mkdir -p "$OUT"

echo "Exporting Ethos Portal as-is to $OUT (region: $REGION)"

# ----- Identity & scope -----
aws sts get-caller-identity > "$OUT/whoami.json"
aws ec2 describe-vpcs --region "$REGION" > "$OUT/vpcs.json"
aws ec2 describe-subnets --region "$REGION" > "$OUT/subnets.json"
aws ec2 describe-vpc-endpoints --region "$REGION" > "$OUT/vpce.json"
aws ec2 describe-security-groups --region "$REGION" > "$OUT/sgs.json"
aws ec2 describe-route-tables --region "$REGION" > "$OUT/routes.json"

# ----- Edge + DNS + CDN -----
aws route53 list-hosted-zones > "$OUT/r53_zones.json"
# loop zones to fetch records
jq -r '.HostedZones[].Id' "$OUT/r53_zones.json" | sed 's#/hostedzone/##' | while read -r HZID; do
  aws route53 list-resource-record-sets --hosted-zone-id "$HZID" > "$OUT/r53_records_${HZID}.json"
done

aws cloudfront list-distributions > "$OUT/cf_distributions.json"
# fetch full config per distribution (origins/behaviors/TLS)
jq -r '.DistributionList.Items[].Id' "$OUT/cf_distributions.json" 2>/dev/null | while read -r DID; do
  aws cloudfront get-distribution --id "$DID" > "$OUT/cf_${DID}.json"
done

# ----- API layer (v2 + v1) -----
aws apigatewayv2 get-apis --region "$REGION" > "$OUT/apigw_v2_apis.json"
# Optional: domain names (custom domains)
aws apigatewayv2 get-domain-names --region "$REGION" > "$OUT/apigw_v2_domains.json"
# loop v2 apis for stages/integrations/routes/authorizers
jq -r '.Items[].ApiId' "$OUT/apigw_v2_apis.json" 2>/dev/null | while read -r API; do
  aws apigatewayv2 get-stages --api-id "$API" --region "$REGION" > "$OUT/apigw_v2_${API}_stages.json"
  aws apigatewayv2 get-integrations --api-id "$API" --region "$REGION" > "$OUT/apigw_v2_${API}_integrations.json"
  aws apigatewayv2 get-routes --api-id "$API" --region "$REGION" > "$OUT/apigw_v2_${API}_routes.json"
  aws apigatewayv2 get-authorizers --api-id "$API" --region "$REGION" > "$OUT/apigw_v2_${API}_authorizers.json"
done

aws apigateway get-rest-apis --region "$REGION" > "$OUT/apigw_v1_apis.json"
aws apigateway get-domain-names --region "$REGION" > "$OUT/apigw_v1_domains.json"
# lightweight per-REST API (full per-method integrations are very heavy; skip for one-time doc)
jq -r '.items[].id' "$OUT/apigw_v1_apis.json" 2>/dev/null | while read -r RID; do
  aws apigateway get-stages --rest-api-id "$RID" --region "$REGION" > "$OUT/apigw_v1_${RID}_stages.json"
  aws apigateway get-resources --rest-api-id "$RID" --region "$REGION" > "$OUT/apigw_v1_${RID}_resources.json"
done

# ----- Load balancer (focus on NLBs) -----
aws elbv2 describe-load-balancers --region "$REGION" > "$OUT/elbv2_lbs.json"
# Filter NLBs for convenience (still keep the full file above)
aws elbv2 describe-load-balancers --region "$REGION" \
  --query 'LoadBalancers[?Type==`network`]' > "$OUT/elbv2_nlbs.json"

# loop NLB ARNs for listeners, attributes, and target groups
jq -r '.[].LoadBalancerArn' "$OUT/elbv2_nlbs.json" 2>/dev/null | while read -r LARN; do
  LID=$(basename "$LARN")
  aws elbv2 describe-listeners --load-balancer-arn "$LARN" --region "$REGION" > "$OUT/elbv2_${LID}_listeners.json"
  aws elbv2 describe-load-balancer-attributes --load-balancer-arn "$LARN" --region "$REGION" > "$OUT/elbv2_${LID}_attrs.json"
  # target groups for this LB
  aws elbv2 describe-target-groups --load-balancer-arn "$LARN" --region "$REGION" > "$OUT/elbv2_${LID}_tgs.json"
  jq -r '.TargetGroups[].TargetGroupArn' "$OUT/elbv2_${LID}_tgs.json" 2>/dev/null | while read -r TGARN; do
    TID=$(basename "$TGARN")
    aws elbv2 describe-target-health --target-group-arn "$TGARN" --region "$REGION" > "$OUT/elbv2_tg_${TID}_health.json"
    aws elbv2 describe-target-group-attributes --target-group-arn "$TGARN" --region "$REGION" > "$OUT/elbv2_tg_${TID}_attrs.json"
  done
done

# ----- EKS control plane & k8s ingress/services -----
aws eks list-clusters --region "$REGION" > "$OUT/eks_clusters.json"
jq -r '.clusters[]' "$OUT/eks_clusters.json" 2>/dev/null | while read -r CL; do
  aws eks describe-cluster --name "$CL" --region "$REGION" > "$OUT/eks_${CL}.json"
  # kubeconfig + cluster scrape (requires your IAM/kubectl can auth to EKS)
  aws eks update-kubeconfig --name "$CL" --region "$REGION" >/dev/null
  kubectl get ingressclass -A -o yaml > "$OUT/eks_${CL}_ingressclass.yaml" || true
  kubectl get ingress -A -o yaml       > "$OUT/eks_${CL}_ingress.yaml" || true
  kubectl get svc -A -o yaml           > "$OUT/eks_${CL}_services.yaml" || true
  kubectl get deploy -A -o yaml        > "$OUT/eks_${CL}_deploys.yaml" || true
done

# ----- Lambda & S3 (PCI-relevant) -----
aws lambda list-functions --region "$REGION" > "$OUT/lambda_functions.json"

aws s3api list-buckets > "$OUT/s3_buckets.json"
jq -r '.Buckets[].Name' "$OUT/s3_buckets.json" | while read -r B; do
  aws s3api get-bucket-encryption --bucket "$B" > "$OUT/s3_${B}_enc.json" 2>/dev/null || true
  aws s3api get-public-access-block --bucket "$B" > "$OUT/s3_${B}_pab.json" 2>/dev/null || true
  aws s3api get-bucket-versioning --bucket "$B" > "$OUT/s3_${B}_ver.json" 2>/dev/null || true
  aws s3api get-bucket-policy-status --bucket "$B" > "$OUT/s3_${B}_policy_status.json" 2>/dev/null || true
  aws s3api get-bucket-ownership-controls --bucket "$B" > "$OUT/s3_${B}_ownership.json" 2>/dev/null || true
done

echo "Done. JSON exports in $OUT"
