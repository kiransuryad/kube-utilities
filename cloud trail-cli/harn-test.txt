Hi All,

Thanks to the GitHub migration team for their excellent coordination and support so far.

‚úÖ Current Status
We have been provided with a test location in the new FIS GitHub where the migrated repositories are available.
We‚Äôve successfully validated access both locally and through our pipelines, confirming that integrations are functioning as expected.

üîÑ Next Steps
Onboarding to capital-markets Organization:
In the upcoming week, we will onboard into the FIS GitHub capital-markets team.
This will allow us to create our child team and follow the standard access pattern used by capital-markets.
Repo Migration:
Once onboarding is complete, the GitHub migration team will migrate the remaining repositories to the capital-markets org over the weekend.
Post-migration, we will update our CI/CD pipelines to point to the new FIS GitHub locations.
Post-Migration Archival:
After cutover, repositories in github.worldpay.com will be archived.
Teams will retain read-only access, and write/edit permissions will be removed.
üõ†Ô∏è Action Required ‚Äì Service Accounts Setup
@Sushanth, @John ‚Äì
Could you please confirm if your teams were able to:

Create Service Accounts in FIS GitHub?
Generate Personal Access Tokens (PATs) for these service accounts?
üìã FIS GitHub Onboarding Checklist
For anyone still waiting to be onboarded to FIS GitHub, please follow the steps below:

Raise access request to FIS GitHub via Dash.
Request creation of FIS GitHub Service Account via ServiceNow.
Once created, retrieve service account credentials (password) from CyberArk.
Login with service account and generate Fine-Grained PATs required for pipeline access.
Raise onboarding request to capital-markets team in FIS GitHub using [this link ‚Äì insert link here].
After migration team confirms cutover is complete, verify access and update your workflows accordingly.
‚ö†Ô∏è Please Note:
The cutover migration is planned for next week, after which write access will be disabled on github.worldpay.com.
Let us know ASAP if you have any concerns or blockers related to this transition.

Thanks & Regards,
Kiran Gonela



----
volumeMounts:
  - name: tls-secret
    mountPath: /etc/x509/https
    readOnly: true

volumes:
  - name: tls-secret
    secret:
      secretName: keycloak-tls

extraVolumeMounts:
  - name: tls-secret
    mountPath: /etc/x509/https
    readOnly: true

extraVolumes:
  - name: tls-secret
    secret:
      secretName: keycloak-tls



extraEnv:
  - name: KC_HTTP_ENABLED
    value: "false"
  - name: KC_HTTPS_PORT
    value: "8443"
  - name: KC_HTTPS_CERTIFICATE_FILE
    value: /etc/x509/https/tls.crt
  - name: KC_HTTPS_CERTIFICATE_KEY_FILE
    value: /etc/x509/https/tls.key
  - name: KC_HOSTNAME
    value: keycloak.test.internal
  - name: KC_HOSTNAME_STRICT
    value: "true"
  - name: KC_HOSTNAME_STRICT_HTTPS
    value: "true"





{{- if .Values.tls.enabled }}
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: {{ .Values.tls.secretName }}
  namespace: {{ .Release.Namespace }}
spec:
  secretName: {{ .Values.tls.secretName }}
  issuerRef:
    name: {{ .Values.tls.issuer }}
    kind: ClusterIssuer
  commonName: {{ .Values.tls.commonName }}
  dnsNames:
    {{- range .Values.tls.dnsNames }}
    - {{ . }}
    {{- end }}
{{- end }}


tls:
  enabled: true
  issuer: cio-ca-issuer
  secretName: keycloak-tls
  commonName: keycloak.test.internal
  dnsNames:
    - keycloak.test.internal



----
#!/bin/bash

echo "Ensuring JFrog imagePullSecret exists..."

# Retrieve secrets from Harness
USERNAME="<+secrets.getValue(\"svc-acct-artifact-secret-username\")>"
PASSWORD="<+secrets.getValue(\"svc-acct-artifact-secret-password\")>"
EMAIL="your@email.com"

# Generate base64-encoded auth string
AUTH_ENCODED=$(echo -n "${USERNAME}:${PASSWORD}" | base64)

# Apply or update the imagePullSecret
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: jfrog-docker-secret
  namespace: tools
type: kubernetes.io/dockerconfigjson
data:
  .dockerconfigjson: $(echo -n '{
    "auths": {
      "edas-docker-snapshot-local.docker.fis.dev": {
        "username": "'${USERNAME}'",
        "password": "'${PASSWORD}'",
        "email": "'${EMAIL}'",
        "auth": "'${AUTH_ENCODED}'"
      }
    }
  }' | base64 -w 0)
EOF



----
#!/bin/bash

echo "Ensuring secret 'jfrog-docker-secret' exists or is updated..."

ENCODED_AUTH=$(echo -n "${HARNESS_JFROG_USERNAME}:${HARNESS_JFROG_API_KEY}" | base64)

cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: jfrog-docker-secret
  namespace: tools
type: kubernetes.io/dockerconfigjson
data:
  .dockerconfigjson: $(echo -n '{
    "auths": {
      "edas-docker-snapshot-local.docker.fis.dev": {
        "username": "'${HARNESS_JFROG_USERNAME}'",
        "password": "'${HARNESS_JFROG_API_KEY}'",
        "email": "your@email.com",
        "auth": "'${ENCODED_AUTH}'"
      }
    }
  }' | base64 -w 0)
EOF



----
Step 1: Update values.yaml in Your Helm Chart
Add this:

imagePullSecrets:
  - name: jfrog-docker-secret
Update your templates/deployment.yaml if it isn‚Äôt already:

spec:
  imagePullSecrets:
    {{- toYaml .Values.imagePullSecrets | nindent 6 }}
This ensures Harness will always use the correct pull secret when deploying the chart.

‚öôÔ∏è Step 2: Add a Shell Script Step in Harness (Before Helm Deploy)
Purpose:

Ensure the secret exists (idempotent), skip if already created.

üìÑ Script Content:

#!/bin/bash

kubectl get secret jfrog-docker-secret -n tools >/dev/null 2>&1

if [ $? -ne 0 ]; then
  echo "Secret not found. Creating..."
  kubectl create secret docker-registry jfrog-docker-secret \
    --docker-server=edas-docker-snapshot-local.docker.fis.dev \
    --docker-username=${HARNESS_JFROG_USERNAME} \
    --docker-password=${HARNESS_JFROG_API_KEY} \
    --docker-email=your@email.com \
    -n tools
else
  echo "Secret already exists. Skipping creation."
fi



---
Step-by-Step: Patch the Running Deployment
1. Create the image pull secret (if not done yet)

kubectl create secret docker-registry jfrog-docker-secret \
  --docker-server=edas-docker-snapshot-local.docker.fis.dev \
  --docker-username=<your-username> \
  --docker-password=<your-api-key> \
  --docker-email=you@example.com \
  -n tools
2. Patch your deployment to use the secret

kubectl patch deployment tools-pod \
  -n tools \
  --type='json' \
  -p='[{"op":"add","path":"/spec/template/spec/imagePullSecrets","value":[{"name":"jfrog-docker-secret"}]}]'
‚úÖ This adds the imagePullSecrets field to your pod spec, without altering anything else.

3. Restart the deployment

kubectl rollout restart deployment tools-pod -n tools
4. Watch pod startup

kubectl get pods -n tools -w
Once you see the pod go from ContainerCreating to Running, you're good!

‚úÖ Once Tested Successfully
Update your Helm chart‚Äôs values.yaml:
imagePullSecrets:
  - name: jfrog-docker-secret
Ensure your deployment.yaml uses:
spec:
  imagePullSecrets:
    {{- toYaml .Values.imagePullSecrets | nindent 6 }}
Push this to Git, and re-deploy using Harness.
