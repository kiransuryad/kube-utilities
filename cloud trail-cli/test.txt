Run the queries via Steampipe:
steampipe query --output csv --file queries.sql
This will create multiple .csv files in your folder.
Generate the final report:
python generate_report.py
You'll get:
aws_inventory_report.xlsx ‚Äî for Excel users
aws_inventory_report.html ‚Äî viewable in any browser




------
Access Verification
 Verify access to new GitHub repositories (UI + CLI).
 Request missing access if needed.
CI/CD Service Account Setup
 Verify existing service accounts have access to new repos.
 Create/update service accounts or tokens as needed.
Update References
 Update pipeline configurations (Jenkins, GitHub Actions, Azure DevOps, etc.) with new repo URLs.
 Update Git URLs in tools like Jenkins, ArgoCD, FluxCD, etc.
 Update any local .git/config or workspace references (for developers or tools).
 Update any scripts or IaC templates that use hardcoded Git URLs.
Validation
 Trigger CI/CD pipelines end-to-end.
 Confirm that pipeline stages can fetch the repo successfully.
 Verify ArgoCD/git-sync-based tools are deploying as expected.
Cleanup (Optional)
 Remove references to old GitHub URLs.
 Archive or decommission old repositories if applicable.

------
‚úÖ Step 1: Export the Vault namespace
export VAULT_NAMESPACE="Caas-Parent/A10003579-Harness"
export VAULT_ADDR="https://your-vault-url"
export VAULT_TOKEN="your-admin-or-root-token"
‚úÖ Step 2: Enable the AppRole auth method (if not already)
vault auth enable approle
If it's already enabled, you‚Äôll get a warning which can be ignored.

‚úÖ Step 3: Enable KV secret engine (if not already)
vault secrets enable -path=kv kv-v2
Verify with:

vault secrets list
‚úÖ Step 4: Create a policy
Create a file harness-policy.hcl:

path "kv/data/harness/*" {
  capabilities = ["read", "create", "update", "delete", "list"]
}

path "kv/metadata/harness/*" {
  capabilities = ["list", "delete"]
}
Apply it:

vault policy write harness-policy harness-policy.hcl
‚úÖ Step 5: Create the AppRole and bind the policy
vault write auth/approle/role/harness-role \
    token_ttl=8760h token_max_ttl=8760h \
    secret_id_ttl=8760h \
    token_policies="harness-policy"
8760h = 1 year
Check role ID:

vault read auth/approle/role/harness-role/role-id
Get secret ID:

vault write -f auth/approle/role/harness-role/secret-id
‚úÖ Step 6: Test by logging in via AppRole
vault write auth/approle/login \
    role_id="<copied-role-id>" \
    secret_id="<copied-secret-id>"
This gives you a Vault token valid for 1 year.

Save this securely, as this token is what Harness can use.

‚úÖ Step 7: Use in Harness
In Harness, go to:

Project ‚Üí Connectors ‚Üí Secrets Manager ‚Üí Add New Vault

Vault URL: https://your-vault-url
Auth Method: AppRole
Role ID: <from Step 5>
Secret ID: <from Step 5>
Vault Namespace: Caas-Parent/A10003579-Harness (if using Enterprise)
KV Version: v2
Secret Path Prefix: kv/harness
Save and test the connection.

üß™ (Optional) Step 8: Store a sample secret in Vault
vault kv put kv/harness/sample-secret \
    username="admin" password="p@ssw0rd"


--------
LDAP Configuration for Keycloak in CIO Environment

Hi Casey & Rajesh,

Hope you're both doing well.

We‚Äôre approaching the testing phase of Keycloak in our new CIO environment, and I had a quick query regarding the LDAP configuration.

Currently, in our EDA Management account, we are using ldap://worldpay.local. However, since we don‚Äôt have access to this LDAP from our new CIO AWS account, we‚Äôll need to connect to an alternative.

Could you please advise on the preferred Active Directory LDAP that we should connect to from the CIO environment? Below is the list I received from the LDAP team‚Äîplease let me know if any of these would be suitable, or if there's a recommended option we should use for our Ethos LDAP setup.

Thank you!

Best regards,
Kiran

-------
GitHub Migration Plan: github.worldpay.com ‚Üí FIS GitHub Enterprise

Current Status & Activities
License Procurement
License request for FIS GitHub Enterprise has been raised with the respective teams.
Procurement is currently in progress.
Access Provisioning
Access request for FIS GitHub has been submitted.
This is currently being processed.
Migration Coordination
Engaged with Kailash and team for detailed planning.
A ServiceNow ticket has been raised with the GitHub migration team for both DTS and EDP organization migrations.
DTS Organization Migration
Current State: Hosted on github.worldpay.com.
Migration Type: Straightforward, as it‚Äôs still within the same platform.
Repository Count: ~405 repositories total.
POC Plan:

Initial Scope: 20 representative repositories selected for a Proof of Concept (POC).
Timeline: Migration team committed to delivering these 20 repos in FIS GitHub by early next week.
Next Step:
Validate the POC repositories once delivered.
Provide confirmation/feedback.
Upon approval, the migration team will proceed with the remaining ~385 repositories.
Final migration timeline: To be confirmed based on POC outcome.
EDP Organization Migration
Current State: Already migrated by Worldpay to their GitHub Cloud instance a week ago.
Decision Pending: Need to confirm the source of truth for EDP migration:
Should the migration be from:
github.worldpay.com (legacy), or
Worldpay GitHub Cloud (new)?
Next Step:
Await confirmation from the application team.
Once confirmed, the migration team will finalize the migration plan and timeline accordingly.

----
echo "<+secrets.getValue(\"KEYCLOAK_ADMIN\")>" | sed -E 's/.*value: (.*)}/\1/' | base64 > /tmp/kc_admin.txt

echo "{value: keycloakadmin}" | awk -F'value: ' '{print $2}' | tr -d '}'


echo "<+secrets.getValue(\"KEYCLOAK_ADMIN\")>" | grep -oP '(?<=value: ).*' > /tmp/kc_admin.txt
cat /tmp/kc_admin.txt



---
replicaCount: 1

image:
  repository: my.jfrog.internal/keycloak/keycloakx
  tag: "21.1.2"
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 8080

ingress:
  enabled: true
  ingressClassName: nginx
  annotations:
    cert-manager.io/cluster-issuer: cio-ca-issuer
    nginx.ingress.kubernetes.io/rewrite-target: /
  hosts:
    - host: keycloak.test.internal
      paths:
        - path: /keycloak
          pathType: Prefix
    - host: <your-nlb-dns>.elb.amazonaws.com
      paths:
        - path: /keycloak
          pathType: Prefix
    - host: <your-alb-dns>.elb.amazonaws.com
      paths:
        - path: /keycloak
          pathType: Prefix
  tls:
    - secretName: keycloakx-tls
      hosts:
        - keycloak.test.internal
        - <your-nlb-dns>.elb.amazonaws.com
        - <your-alb-dns>.elb.amazonaws.com

extraEnv: |
  - name: KEYCLOAK_ADMIN
    value: <+secrets.getValue("keycloak-admin-username")>
  - name: KEYCLOAK_ADMIN_PASSWORD
    value: <+secrets.getValue("keycloak-admin-password")>
  - name: KC_DB
    value: postgres
  - name: KC_DB_URL_HOST
    value: <+secrets.getValue("keycloak-db-host")>
  - name: KC_DB_URL_DATABASE
    value: keycloak
  - name: KC_DB_USERNAME
    value: <+secrets.getValue("keycloak-db-username")>
  - name: KC_DB_PASSWORD
    value: <+secrets.getValue("keycloak-db-password")>
  - name: KC_PROXY
    value: edge
  - name: KC_HTTP_ENABLED
    value: "true"
  - name: KC_HOSTNAME_STRICT
    value: "false"
  - name: KC_HOSTNAME_STRICT_HTTPS
    value: "false"

resources:
  requests:
    cpu: 250m
    memory: 512Mi
  limits:
    cpu: 500m
    memory: 1Gi



-----------
replicaCount: 1

image:
  repository: httpd
  tag: 2.4-alpine
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: true
  className: nginx
  annotations:
    cert-manager.io/cluster-issuer: cio-ca-issuer
  hosts:
    - host: sample.test.internal
      paths:
        - path: /sample
          pathType: Prefix
  tls:
    - secretName: sample-app-tls
      hosts:
        - sample.test.internal




-------
curl -k https://<NLB-DNS> -H "Host: sample.test.internal"


----
controller:
  replicaCount: 2

  service:
    enabled: true
    externalTrafficPolicy: Local

    annotations:
      service.beta.kubernetes.io/aws-load-balancer-scheme: "internal"
      service.beta.kubernetes.io/aws-load-balancer-internal: "true"
      service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
      service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: "ip"
      service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"

  ingressClassResource:
    name: nginx
    enabled: true
    default: true

  metrics:
    enabled: true

  admissionWebhooks:
    enabled: true

defaultBackend:
  enabled: true



-----
git add ${CHART_NAME}/chart || true

echo "Checking if there are any staged changes..."
if ! git diff --cached --quiet; then
  git commit -m "Overlay Sync: ${CHART_NAME} ${CHART_VERSION} from upstream main"
  git push https://${BB_USER}:${BB_TOKEN}@bitbucket.fis.dev/scm/~lc5736691/hydra-helm-overlays.git HEAD:${OVERLAY_FEATURE_BRANCH}
else
  echo "No changes to commit. Skipping push."
fi


----
stage('Sync Chart (Preserve Overlay Customizations - Option B)') {
    sh '''
    mkdir -p overlays/${CHART_NAME}/chart

    echo "Backing up overlay-managed files (values-*.yaml, custom-values.yaml, patches/, overlays/)..."
    mkdir -p tmp-preserve
    cp -a overlays/${CHART_NAME}/chart/values-*.yaml tmp-preserve/ || true
    cp -a overlays/${CHART_NAME}/chart/custom-values.yaml tmp-preserve/ || true
    cp -a overlays/${CHART_NAME}/chart/patches tmp-preserve/ || true
    cp -a overlays/${CHART_NAME}/chart/overlays tmp-preserve/ || true

    echo "Removing old chart/ contents..."
    rm -rf overlays/${CHART_NAME}/chart/*

    echo "Copying upstream chart into overlays..."
    cp -a upstream/mirror/${CHART_NAME}/${CHART_VERSION}/${CHART_NAME}/* overlays/${CHART_NAME}/chart/

    echo "Restoring preserved overlay custom files..."
    cp -a tmp-preserve/* overlays/${CHART_NAME}/chart/ || true
    cp -a tmp-preserve/patches overlays/${CHART_NAME}/chart/ || true
    cp -a tmp-preserve/overlays overlays/${CHART_NAME}/chart/ || true
    rm -rf tmp-preserve
    '''
}



---
@Library(['common-lib@c3-stable']) _

parameters {
    string(name: 'CHART_NAME', description: 'Helm chart name (e.g. nginx, keycloak)')
    string(name: 'CHART_VERSION', description: 'Helm chart version (e.g. 1.21.0)')
    string(name: 'OVERLAY_FEATURE_BRANCH', description: 'Feature branch name to create/push in hydra-helm-overlays')
}

def label = "hydra-overlay-sync-${UUID.randomUUID().toString()}"
String podTemplateString = '''...''' // keep your pod spec as-is (aws container)

podTemplate(
    label: label,
    yaml: podTemplateString,
    serviceAccount: 'jenkins',
    runAsUser: '1000'
) {
    node(label) {
        environment {
            UPSTREAM_GIT_URL = "https://bitbucket.fis.dev/scm/~lc5736691/hydra-helm-upstreams.git"
            OVERLAYS_GIT_URL = "https://bitbucket.fis.dev/scm/~lc5736691/hydra-helm-overlays.git"
            OVERLAYS_MAIN_BRANCH = 'develop'
        }

        stage('Clone Repositories') {
            withCredentials([usernamePassword(credentialsId: 'kiran-creds', usernameVariable: 'BB_USER', passwordVariable: 'BB_TOKEN')]) {
                sh '''
                rm -rf upstream overlays

                echo "Cloning upstream repo (read-only)..."
                git clone --branch main https://${BB_USER}:${BB_TOKEN}@bitbucket.fis.dev/scm/~lc5736691/hydra-helm-upstreams.git upstream

                echo "Cloning overlays repo (develop)..."
                git clone https://${BB_USER}:${BB_TOKEN}@bitbucket.fis.dev/scm/~lc5736691/hydra-helm-overlays.git overlays
                '''
            }
        }

        stage('Create or Checkout Feature Branch') {
            dir('overlays') {
                withCredentials([usernamePassword(credentialsId: 'kiran-creds', usernameVariable: 'BB_USER', passwordVariable: 'BB_TOKEN')]) {
                    sh '''
                    git checkout ${OVERLAYS_MAIN_BRANCH}
                    git checkout -b ${OVERLAY_FEATURE_BRANCH} || git checkout ${OVERLAY_FEATURE_BRANCH}
                    '''
                }
            }
        }

        stage('Sync Chart (Preserve Overlay Customizations)') {
            sh '''
            mkdir -p overlays/${CHART_NAME}/chart

            echo "Syncing upstream chart into overlays/${CHART_NAME}/chart/..."
            rsync -av --delete \
              --exclude 'values-prod.yaml' \
              --exclude 'values-dev.yaml' \
              --exclude 'custom-values.yaml' \
              --exclude 'patches/' \
              --exclude 'overlays/' \
              upstream/mirror/${CHART_NAME}/${CHART_VERSION}/${CHART_NAME}/ \
              overlays/${CHART_NAME}/chart/
            '''
        }

        stage('Commit and Push Feature Branch') {
            dir('overlays') {
                withCredentials([usernamePassword(credentialsId: 'kiran-creds', usernameVariable: 'BB_USER', passwordVariable: 'BB_TOKEN')]) {
                    sh '''
                    git config user.name "${BB_USER}"
                    git config user.email "${BB_USER}@yourorg.com"

                    git add ${CHART_NAME}/chart
                    git commit -m "Overlay Sync: ${CHART_NAME} ${CHART_VERSION} from upstream"
                    git push https://${BB_USER}:${BB_TOKEN}@bitbucket.fis.dev/scm/~lc5736691/hydra-helm-overlays.git HEAD:${OVERLAY_FEATURE_BRANCH}
                    '''
                }
            }
        }
    }
}


-------
@Library(['common-lib@c3-stable']) _

parameters {
    string(name: 'CHART_NAME', description: 'Helm chart name (e.g. nginx, keycloak)')
    string(name: 'CHART_VERSION', description: 'Helm chart version (e.g. 1.21.0)')
    string(name: 'OVERLAY_FEATURE_BRANCH', description: 'Feature branch name to create/push in hydra-helm-overlays')
}

def label = "hydra-helm-pod-${UUID.randomUUID().toString()}"
String podTemplateString = '''...''' // leave your existing podTemplate string here

podTemplate(
    label: label,
    yaml: podTemplateString,
    serviceAccount: 'jenkins',
    runAsUser: '1000'
) {
    node(label) {
        environment {
            UPSTREAM_GIT_URL = "https://bitbucket.fis.dev/scm/~lc5736691/hydra-helm-upstreams.git"
            OVERLAYS_GIT_URL = "https://bitbucket.fis.dev/scm/~lc5736691/hydra-helm-overlays.git"
            OVERLAYS_MAIN_BRANCH = 'develop'
        }

        stage('Clone Repositories using HTTPS') {
            environment {
                GIT_SSL_NO_VERIFY = "true"
            }

            withCredentials([usernamePassword(credentialsId: 'kiran-creds', usernameVariable: 'BB_USER', passwordVariable: 'BB_TOKEN')]) {
                sh '''
                rm -rf upstream overlays

                echo "Cloning upstream (read-only) repo..."
                git clone --branch main https://${BB_USER}:${BB_TOKEN}@bitbucket.fis.dev/scm/~lc5736691/hydra-helm-upstreams.git upstream

                echo "Cloning overlays repo..."
                git clone https://${BB_USER}:${BB_TOKEN}@bitbucket.fis.dev/scm/~lc5736691/hydra-helm-overlays.git overlays
                '''
            }
        }

        stage('Create/Checkout Overlay Feature Branch') {
            dir('overlays') {
                withCredentials([usernamePassword(credentialsId: 'kiran-creds', usernameVariable: 'BB_USER', passwordVariable: 'BB_TOKEN')]) {
                    sh '''
                    git checkout ${OVERLAYS_MAIN_BRANCH}
                    git checkout -b ${OVERLAY_FEATURE_BRANCH} || git checkout ${OVERLAY_FEATURE_BRANCH}
                    '''
                }
            }
        }

        stage('Sync Chart Folder from Upstream Repo') {
            sh '''
            rm -rf overlays/${CHART_NAME}/chart
            mkdir -p overlays/${CHART_NAME}/chart

            cp -R upstream/mirror/${CHART_NAME}/${CHART_VERSION}/${CHART_NAME}/* overlays/${CHART_NAME}/chart/
            '''
        }

        stage('Commit & Push to Overlay Feature Branch') {
            dir('overlays') {
                withCredentials([usernamePassword(credentialsId: 'kiran-creds', usernameVariable: 'BB_USER', passwordVariable: 'BB_TOKEN')]) {
                    sh '''
                    git config user.name "${BB_USER}"
                    git config user.email "${BB_USER}@yourorg.com"

                    git add ${CHART_NAME}/chart
                    git commit -m "Overlay Sync: ${CHART_NAME} ${CHART_VERSION} from upstream main"
                    git push https://${BB_USER}:${BB_TOKEN}@bitbucket.fis.dev/scm/~lc5736691/hydra-helm-overlays.git HEAD:${OVERLAY_FEATURE_BRANCH}
                    '''
                }
            }
        }
    }
}




-----
stage('Push Helm Chart to Bitbucket (versioned + latest)') {
  withCredentials([usernamePassword(credentialsId: 'kiran-creds', usernameVariable: 'BB_USER', passwordVariable: 'BB_TOKEN')]) {
    container('jdk11') {
      sh '''
        set -eo pipefail

        git config --global user.email "kiran.gonela@fisglobal.com"
        git config --global user.name "Kiran G"

        echo "Cloning target Bitbucket repo: ${TARGET_BITBUCKET_REPO}"
        git clone https://${BB_USER}:${BB_TOKEN}@bitbucket.fis.dev/scm/~lc5736691/${TARGET_BITBUCKET_REPO}.git target-repo
        cd target-repo

        CHART_DIR="mirror/${SRC_CHART_NAME}/${SRC_CHART_VERSION}"
        LATEST_DIR="mirror/${SRC_CHART_NAME}/latest"

        echo "Preparing chart directories..."
        mkdir -p ${CHART_DIR}
        rm -rf ${LATEST_DIR}
        mkdir -p ${LATEST_DIR}

        echo "Copying chart contents into versioned and latest directories..."
        cp -R ../${SRC_CHART_NAME}/* ${CHART_DIR}/
        cp -R ../${SRC_CHART_NAME}/* ${LATEST_DIR}/

        echo "Committing and pushing changes..."
        git add mirror/${SRC_CHART_NAME}
        git commit -m "Mirror: ${SRC_CHART_NAME} ${SRC_CHART_VERSION} from ${SRC_REPO_URL}"
        git push https://${BB_USER}:${BB_TOKEN}@bitbucket.fis.dev/scm/~lc5736691/${TARGET_BITBUCKET_REPO}.git HEAD
      '''
    }
  }
}



-------
Subject: Request to Configure Vault Kubernetes Auth Backend or Grant Temporary Admin Policy
Hi [Vault Admin / Platform Team],

I'm currently working on integrating our EKS workloads with HashiCorp Vault, specifically to enable the Vault Agent Injector to pull secrets (like Keycloak admin credentials and internal TLS certificates) using the Kubernetes authentication method.

However, I've hit a blocker while trying to configure the Kubernetes auth backend from the CLI on our bastion host using my Vault token.

üîç Problem
Attempts to run the following fail with 403 Forbidden errors:

vault auth enable -path=kubernetes -max-lease-ttl=24h kubernetes

vault write auth/kubernetes/config \
  token_reviewer_jwt="<EKS_JWT_TOKEN>" \
  kubernetes_host="<EKS_API_URL>" \
  kubernetes_ca_cert="<CLUSTER_CA_CERT>" \
  issuer="https://kubernetes.default.svc"
The token I‚Äôm using is authenticated under namespace:
CaaS-Parent/A10003579-Keycloak

Even after switching to:
CaaS-Parent (where the auth/kubernetes path is enabled), the same error persists ‚Äî confirming it‚Äôs a permissions issue.

‚úÖ What We Need
Please help us with one of the following:

Option 1: You configure Kubernetes auth on our behalf

Run these (we will supply JWT, CA, and API server values as needed):

vault write auth/kubernetes/config \
  token_reviewer_jwt="<...>" \
  kubernetes_host="https://..." \
  kubernetes_ca_cert="-----BEGIN CERTIFICATE-----..." \
  issuer="https://kubernetes.default.svc"
And ensure the following role exists:

vault write auth/kubernetes/role/k8s-general \
  bound_service_account_names="*" \
  bound_service_account_namespaces="*" \
  policies="k8s-read-eks-apps" \
  ttl="24h"
Option 2: Grant my token temporary access to configure Kubernetes auth

Please assign my token (or identity) the following policy within CaaS-Parent namespace:

# Enable/Configure Kubernetes auth backend
path "sys/auth/kubernetes" {
  capabilities = ["create", "update"]
}
path "auth/kubernetes/config" {
  capabilities = ["create", "update"]
}

# Manage Vault roles under Kubernetes auth
path "auth/kubernetes/role/*" {
  capabilities = ["create", "update", "read", "delete", "list"]
}
Once this is done, I can finish setting up the Vault integration for the EKS workloads securely.

Please let me know if you'd prefer me to provide the JWT and CA cert values for you to configure directly. I‚Äôm happy to assist with validation after the setup.

Thanks in advance!

Best regards,

---
vault token create \
  -namespace="CaaS-Parent/A10003579-Keycloak" \
  -orphan \
  -policy="default" \
  -policy="k8s-read-eks-apps" \
  -period=24h


---
Steps to Set Up a Dedicated Namespace

kubectl create namespace vault-auth
kubectl create serviceaccount vault-auth-setup -n vault-auth
Then retrieve the values for Vault:

JWT_TOKEN=$(kubectl create token vault-auth-setup -n vault-auth)
K8S_CA_CERT=$(kubectl get configmap kube-root-ca.crt -n vault-auth -o jsonpath="{.data.ca\.crt}")
K8S_HOST=$(kubectl config view --minify -o jsonpath="{.clusters[0].cluster.server}")


---
Updated Steps (Child Namespace Scope)

Here‚Äôs what you need to do next:

1. ‚úÖ Enable Kubernetes Auth within your namespace
vault auth enable -path=kubernetes kubernetes
This enables the Kubernetes auth backend scoped to your namespace.

2. ‚úÖ Configure the Kubernetes Auth Backend
Now the previous vault write should work:

vault write auth/kubernetes/config \
  token_reviewer_jwt="${JWT_TOKEN}" \
  kubernetes_host="${K8S_HOST}" \
  kubernetes_ca_cert="${K8S_CA_CERT}" \
  issuer="https://kubernetes.default.svc"
‚úÖ This will succeed now because you‚Äôre operating inside your own namespace.

3. ‚úÖ Continue with the Role + Secret Setup
vault write auth/kubernetes/role/k8s-general \
  bound_service_account_names="*" \
  bound_service_account_namespaces="*" \
  policies="k8s-read-eks-apps" \
  ttl="24h"

vault kv put eks-apps/prod/keycloak/admin username="admin" password="supersecret123"

---
Update your Vault policy to include this:

# file: vault-admin-k8s-setup.hcl

# For setting up Kubernetes auth backend
path "auth/kubernetes/config" {
  capabilities = ["create", "update"]
}

# For creating roles that map K8s SAs to policies
path "auth/kubernetes/role/*" {
  capabilities = ["create", "update", "read", "delete", "list"]
}
Then apply:

vault policy write vault-admin-k8s-setup vault-admin-k8s-setup.hcl

----
#!/bin/bash

set -e

VAULT_ADDR="${VAULT_ADDR:-http://127.0.0.1:8200}"
VAULT_NAMESPACE="${VAULT_NAMESPACE:-root}"

ENGINE_PATH="eks-apps"
POLICY_NAME="k8s-read-eks-apps"
ROLE_NAME="k8s-general"

echo "üîê [1/6] Enabling new KV v2 secrets engine at path: ${ENGINE_PATH}/"

vault secrets enable -path="${ENGINE_PATH}" -version=2 kv || echo "üü° Already enabled"

echo "üìú [2/6] Writing Vault policy: ${POLICY_NAME}"

cat <<EOF | vault policy write ${POLICY_NAME} -
path "${ENGINE_PATH}/data/*" {
  capabilities = ["read"]
}
EOF

echo "üîë [3/6] Extracting Kubernetes auth details from cluster..."

JWT_TOKEN=$(kubectl get secret $(kubectl get sa default -n default -o jsonpath="{.secrets[0].name}") -n default -o jsonpath="{.data.token}" | base64 -d)
K8S_HOST=$(kubectl config view --minify -o jsonpath="{.clusters[0].cluster.server}")
K8S_CA_CERT=$(kubectl get secret $(kubectl get sa default -n default -o jsonpath="{.secrets[0].name}") -n default -o jsonpath="{.data['ca\.crt']}" | base64 -d)

echo "‚öôÔ∏è [4/6] Configuring Vault Kubernetes auth backend"

vault write auth/kubernetes/config \
  token_reviewer_jwt="${JWT_TOKEN}" \
  kubernetes_host="${K8S_HOST}" \
  kubernetes_ca_cert="${K8S_CA_CERT}" \
  issuer="https://kubernetes.default.svc"

echo "üîó [5/6] Creating Vault role: ${ROLE_NAME} (bound to all SAs & namespaces)"

vault write auth/kubernetes/role/${ROLE_NAME} \
  bound_service_account_names="*" \
  bound_service_account_namespaces="*" \
  policies="${POLICY_NAME}" \
  ttl="24h"

echo "üîê [6/6] Storing a sample secret at: ${ENGINE_PATH}/prod/keycloak/admin"

vault kv put ${ENGINE_PATH}/prod/keycloak/admin username="admin" password="supersecret123"

echo "‚úÖ Vault Kubernetes integration complete!"




--------
Quick Test Plan ‚Äî Certificate Issuance

üìÑ Step 1: Create a Test Certificate Resource
Here‚Äôs a simple manifest that will request a TLS cert using your cio-ca-issuer.

# test-certificate.yaml
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: test-tls
  namespace: default
spec:
  secretName: test-tls-secret
  duration: 2160h # 90 days
  renewBefore: 360h # 15 days
  commonName: test.keycloak.internal
  dnsNames:
    - test.keycloak.internal
  issuerRef:
    name: cio-ca-issuer
    kind: ClusterIssuer
Apply it:

kubectl apply -f test-certificate.yaml
üîç Step 2: Validate Certificate Status
Check if cert-manager successfully issued it:

kubectl get certificate test-tls -n default
Expected output:

NAME        READY   SECRET             AGE
test-tls    True    test-tls-secret    1m
If READY is not True, inspect events:

kubectl describe certificate test-tls -n default
kubectl get events -n default --sort-by=.metadata.creationTimestamp
üîê Step 3: Inspect the Generated Secret
kubectl get secret test-tls-secret -n default -o yaml
Should contain:

tls.crt ‚Üí Certificate
tls.key ‚Üí Private key
Optional: Decode and inspect the certificate:

kubectl get secret test-tls-secret -n default -o jsonpath='{.data.tls\.crt}' | base64 -d | openssl x509 -noout -text
Check:

CN = test.keycloak.internal
Validity period = 90 days
Issuer = cio.internal

-----
chart.yaml
---

apiVersion: v2
name: cert-bootstrap
description: Bootstrap internal self-signed CA and ClusterIssuer for cert-manager
type: application
version: 0.1.0
appVersion: "1.0"


vaules.yaml
-----

bootstrapCerts:
  enabled: true
  caCommonName: "cio.internal"
  duration: "8760h"         # 1 year
  renewBefore: "720h"       # 30 days
  caSecretName: "cio-internal-ca-secret"
  clusterIssuerName: "cio-ca-issuer"
  certificateName: "cio-internal-ca"
  namespace: "cert-manager"




-----

---
selfsigned-cluster-issuer.yaml
---
{{- if .Values.bootstrapCerts.enabled }}
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: selfsigned-cluster-issuer
spec:
  selfSigned: {}
{{- end }}


------

----
cio-ca-certificate.yaml
----

{{- if .Values.bootstrapCerts.enabled }}
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: cio-internal-ca
  namespace: cert-manager
spec:
  isCA: true
  commonName: "{{ .Values.bootstrapCerts.caCommonName }}"
  secretName: "{{ .Values.bootstrapCerts.caSecretName }}"
  duration: {{ .Values.bootstrapCerts.duration | quote }}
  renewBefore: {{ .Values.bootstrapCerts.renewBefore | quote }}
  issuerRef:
    name: selfsigned-cluster-issuer
    kind: ClusterIssuer
{{- end }}


------

----
cio-ca-issuer.yaml
----

{{- if .Values.bootstrapCerts.enabled }}
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: {{ .Values.bootstrapCerts.clusterIssuerName }}
spec:
  ca:
    secretName: "{{ .Values.bootstrapCerts.caSecretName }}"
{{- end }}

